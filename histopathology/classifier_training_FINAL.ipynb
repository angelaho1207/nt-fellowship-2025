{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf4b28a-b40e-4ffb-82c4-c59f554ae001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T00:17:12.215844Z",
     "iopub.status.busy": "2025-06-17T00:17:12.215550Z",
     "iopub.status.idle": "2025-06-17T00:17:24.440915Z",
     "shell.execute_reply": "2025-06-17T00:17:24.440239Z",
     "shell.execute_reply.started": "2025-06-17T00:17:12.215821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breakhis_full.zip\n",
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "# Download data from S3 bucket\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'breakhis-dataset'\n",
    "response = s3.list_objects_v2(Bucket='breakhis-dataset')\n",
    "for obj in response.get('Contents', []):\n",
    "    print(obj['Key'])\n",
    "object_key = 'breakhis_full.zip'\n",
    "local_filename = 'breakhis-dataset.zip'\n",
    "\n",
    "s3.download_file(bucket_name, object_key, local_filename)\n",
    "print(\"Download complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fc85f9-1b8a-470a-946f-5fdf233915c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T00:17:24.442531Z",
     "iopub.status.busy": "2025-06-17T00:17:24.441869Z",
     "iopub.status.idle": "2025-06-17T00:18:10.608131Z",
     "shell.execute_reply": "2025-06-17T00:18:10.607560Z",
     "shell.execute_reply.started": "2025-06-17T00:17:24.442505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzip complete!\n"
     ]
    }
   ],
   "source": [
    "# Unzip dataset\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "with zipfile.ZipFile(local_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall('breakhis')  # extracts to folder named breakhis\n",
    "\n",
    "print(\"Unzip complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdef45e6-4958-4fc2-bbbb-8528bbcf7366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T00:18:14.976062Z",
     "iopub.status.busy": "2025-06-17T00:18:14.975514Z",
     "iopub.status.idle": "2025-06-17T00:18:14.979674Z",
     "shell.execute_reply": "2025-06-17T00:18:14.979175Z",
     "shell.execute_reply.started": "2025-06-17T00:18:14.976037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user\n",
      "['.bashrc', 'user-default-efs', '.sagemaker_sql_editor_api_cache', '.local', '.ipython', '.npm', '.jupyter', 'Untitled.ipynb', '.ipynb_checkpoints', '.cache', '.config', '.virtual_documents', 'breast-cancer-tissue-labeling.ipynb', 'breakhis-dataset.zip', 'breakhis']\n"
     ]
    }
   ],
   "source": [
    "# Verify directories\n",
    "print(os.getcwd())\n",
    "print(os.listdir('/home/sagemaker-user'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2873d2c-922d-4f7a-adb9-086104505a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T00:18:18.126327Z",
     "iopub.status.busy": "2025-06-17T00:18:18.125990Z",
     "iopub.status.idle": "2025-06-17T00:18:18.130953Z",
     "shell.execute_reply": "2025-06-17T00:18:18.130457Z",
     "shell.execute_reply.started": "2025-06-17T00:18:18.126307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists? True\n",
      "Is directory? True\n",
      "Contents: ['Folds.csv', 'BreaKHis_v1']\n"
     ]
    }
   ],
   "source": [
    "path = '/home/sagemaker-user/breakhis/BreakHis_dataset'\n",
    "print(\"Exists?\", os.path.exists(path))\n",
    "print(\"Is directory?\", os.path.isdir(path))\n",
    "print(\"Contents:\", os.listdir(path) if os.path.exists(path) else \"Path not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acefd87f-c9a8-4c26-ac14-392459395c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T00:18:21.598159Z",
     "iopub.status.busy": "2025-06-17T00:18:21.597839Z",
     "iopub.status.idle": "2025-06-17T00:18:21.601694Z",
     "shell.execute_reply": "2025-06-17T00:18:21.601232Z",
     "shell.execute_reply.started": "2025-06-17T00:18:21.598137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of breast:\n",
      "['malignant', 'README.txt', 'benign', 'count_files.sh']\n"
     ]
    }
   ],
   "source": [
    "breast_path = '/home/sagemaker-user/breakhis/BreakHis_dataset/BreaKHis_v1/BreaKHis_v1/histology_slides/breast'\n",
    "\n",
    "print(\"Contents of breast:\")\n",
    "print(os.listdir(breast_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb26ca9-c5e4-418f-83e5-ba586c35aa6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T00:22:25.778437Z",
     "iopub.status.busy": "2025-06-17T00:22:25.778114Z",
     "iopub.status.idle": "2025-06-17T00:22:25.782023Z",
     "shell.execute_reply": "2025-06-17T00:22:25.781498Z",
     "shell.execute_reply.started": "2025-06-17T00:22:25.778416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/sagemaker-user/breast_cancer_detection')\n",
    "print('config.json' in os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fe95641-37c4-4323-bfe6-76e28b767bac",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-17T00:22:35.617150Z",
     "iopub.status.busy": "2025-06-17T00:22:35.616828Z",
     "iopub.status.idle": "2025-06-17T00:22:35.769965Z",
     "shell.execute_reply": "2025-06-17T00:22:35.769385Z",
     "shell.execute_reply.started": "2025-06-17T00:22:35.617129Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"BCDensenet\",\n",
      "    \"n_gpu\": 1,\n",
      "\n",
      "    \"arch\": {\n",
      "        \"type\": \"densenet121\",\n",
      "        \"args\": {}\n",
      "    },\n",
      "    \"data_loader\": {\n",
      "        \"type\": \"BCDataLoader\",\n",
      "        \"args\":{\n",
      "            \"data_dir\": \"data/BreaKHis_v1/BreaKHis_v1/histology_slides/breast\",\n",
      "            \"batch_size\": 16,\n",
      "            \"shuffle\": true,\n",
      "            \"validation_split\": 0.1,\n",
      "            \"num_workers\": 2\n",
      "        }\n",
      "    },\n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\",\n",
      "        \"args\":{\n",
      "            \"lr\": 0.001,\n",
      "            \"weight_decay\": 0,\n",
      "            \"amsgrad\": true\n",
      "        }\n",
      "    },\n",
      "    \"loss\": \"cross_entropy\",\n",
      "    \"metrics\": [\n",
      "        \"accuracy\", \"top_k_acc\"\n",
      "    ],\n",
      "    \"lr_scheduler\": {\n",
      "        \"type\": \"StepLR\",\n",
      "        \"args\": {\n",
      "            \"step_size\": 20,\n",
      "            \"gamma\": 0.1\n",
      "        }\n",
      "    },\n",
      "    \"trainer\": {\n",
      "        \"epochs\": 15,\n",
      "\n",
      "        \"save_dir\": \"saved/\",\n",
      "        \"save_period\": 1,\n",
      "        \"verbosity\": 2,\n",
      "        \n",
      "        \"monitor\": \"min val_loss\",\n",
      "        \"early_stop\": 10,\n",
      "\n",
      "        \"tensorboard\": true\n",
      "    }\n",
      "}\n",
      "/home/sagemaker-user/breast_cancer_detection\n",
      "['.git', '.gitignore', 'License', 'README.md', 'base', 'config.json', 'data_loader', 'images', 'logger', 'model', 'parse_config.py', 'requirements.txt', 'saved', 'test.py', 'train.py', 'trainer', 'utils']\n",
      "Config file updated!\n"
     ]
    }
   ],
   "source": [
    "# Update config file\n",
    "!cat config.json\n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n",
    "import json\n",
    "\n",
    "config_path = 'config.json'\n",
    "\n",
    "# Load config\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Update data directory to output path\n",
    "config['data_loader']['args']['data_dir'] = '/home/sagemaker-user/breakhis/BreakHis_dataset/BreaKHis_v1/BreaKHis_v1/histology_slides/breast'\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(\"Config file updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ce430b-876e-409f-9955-ef4af036cd4c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-17T00:23:56.426870Z",
     "iopub.status.busy": "2025-06-17T00:23:56.426524Z",
     "iopub.status.idle": "2025-06-17T00:59:36.655474Z",
     "shell.execute_reply": "2025-06-17T00:59:36.654865Z",
     "shell.execute_reply.started": "2025-06-17T00:23:56.426841Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/sagemaker-user/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|███████████████████████████████████████| 30.8M/30.8M [00:00<00:00, 255MB/s]\n",
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n",
      "2025-06-17 00:24:04.026931: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-17 00:24:04.211213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750119844.234307    1506 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750119844.244861    1506 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-17 00:24:04.448086: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "generated new fontManager\n",
      "/home/sagemaker-user/breast_cancer_detection/utils/util.py:59: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/home/sagemaker-user/breast_cancer_detection/utils/util.py:60: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/home/sagemaker-user/breast_cancer_detection/utils/util.py:61: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n",
      "Train Epoch: 1 [0/7119 (0%)] Loss: 0.691122\n",
      "Train Epoch: 1 [64/7119 (1%)] Loss: 1.094450\n",
      "Train Epoch: 1 [128/7119 (2%)] Loss: 0.667359\n",
      "Train Epoch: 1 [192/7119 (3%)] Loss: 0.626675\n",
      "Train Epoch: 1 [256/7119 (4%)] Loss: 0.562351\n",
      "Train Epoch: 1 [320/7119 (4%)] Loss: 0.623588\n",
      "Train Epoch: 1 [384/7119 (5%)] Loss: 0.501587\n",
      "Train Epoch: 1 [448/7119 (6%)] Loss: 0.613940\n",
      "Train Epoch: 1 [512/7119 (7%)] Loss: 0.498388\n",
      "Train Epoch: 1 [576/7119 (8%)] Loss: 0.498065\n",
      "Train Epoch: 1 [640/7119 (9%)] Loss: 0.436342\n",
      "Train Epoch: 1 [704/7119 (10%)] Loss: 0.460112\n",
      "Train Epoch: 1 [768/7119 (11%)] Loss: 0.492042\n",
      "Train Epoch: 1 [832/7119 (12%)] Loss: 0.352283\n",
      "Train Epoch: 1 [896/7119 (13%)] Loss: 0.552373\n",
      "Train Epoch: 1 [960/7119 (13%)] Loss: 0.554104\n",
      "Train Epoch: 1 [1024/7119 (14%)] Loss: 0.707128\n",
      "Train Epoch: 1 [1088/7119 (15%)] Loss: 0.479162\n",
      "Train Epoch: 1 [1152/7119 (16%)] Loss: 0.368331\n",
      "Train Epoch: 1 [1216/7119 (17%)] Loss: 0.384964\n",
      "Train Epoch: 1 [1280/7119 (18%)] Loss: 0.525834\n",
      "Train Epoch: 1 [1344/7119 (19%)] Loss: 0.509696\n",
      "Train Epoch: 1 [1408/7119 (20%)] Loss: 0.425360\n",
      "Train Epoch: 1 [1472/7119 (21%)] Loss: 0.599491\n",
      "Train Epoch: 1 [1536/7119 (22%)] Loss: 0.379564\n",
      "Train Epoch: 1 [1600/7119 (22%)] Loss: 0.447627\n",
      "Train Epoch: 1 [1664/7119 (23%)] Loss: 0.578614\n",
      "Train Epoch: 1 [1728/7119 (24%)] Loss: 0.719150\n",
      "Train Epoch: 1 [1792/7119 (25%)] Loss: 0.339065\n",
      "Train Epoch: 1 [1856/7119 (26%)] Loss: 0.459996\n",
      "Train Epoch: 1 [1920/7119 (27%)] Loss: 0.350259\n",
      "Train Epoch: 1 [1984/7119 (28%)] Loss: 0.383293\n",
      "Train Epoch: 1 [2048/7119 (29%)] Loss: 0.515574\n",
      "Train Epoch: 1 [2112/7119 (30%)] Loss: 0.316671\n",
      "Train Epoch: 1 [2176/7119 (31%)] Loss: 0.308544\n",
      "Train Epoch: 1 [2240/7119 (31%)] Loss: 0.486197\n",
      "Train Epoch: 1 [2304/7119 (32%)] Loss: 0.705965\n",
      "Train Epoch: 1 [2368/7119 (33%)] Loss: 0.490346\n",
      "Train Epoch: 1 [2432/7119 (34%)] Loss: 0.285763\n",
      "Train Epoch: 1 [2496/7119 (35%)] Loss: 0.529963\n",
      "Train Epoch: 1 [2560/7119 (36%)] Loss: 0.522707\n",
      "Train Epoch: 1 [2624/7119 (37%)] Loss: 0.454473\n",
      "Train Epoch: 1 [2688/7119 (38%)] Loss: 0.552079\n",
      "Train Epoch: 1 [2752/7119 (39%)] Loss: 0.566678\n",
      "Train Epoch: 1 [2816/7119 (40%)] Loss: 0.361736\n",
      "Train Epoch: 1 [2880/7119 (40%)] Loss: 0.274849\n",
      "Train Epoch: 1 [2944/7119 (41%)] Loss: 0.378133\n",
      "Train Epoch: 1 [3008/7119 (42%)] Loss: 0.433120\n",
      "Train Epoch: 1 [3072/7119 (43%)] Loss: 0.310787\n",
      "Train Epoch: 1 [3136/7119 (44%)] Loss: 0.545098\n",
      "Train Epoch: 1 [3200/7119 (45%)] Loss: 0.282459\n",
      "Train Epoch: 1 [3264/7119 (46%)] Loss: 0.373851\n",
      "Train Epoch: 1 [3328/7119 (47%)] Loss: 0.599207\n",
      "Train Epoch: 1 [3392/7119 (48%)] Loss: 0.437904\n",
      "Train Epoch: 1 [3456/7119 (49%)] Loss: 0.513577\n",
      "Train Epoch: 1 [3520/7119 (49%)] Loss: 0.262589\n",
      "Train Epoch: 1 [3584/7119 (50%)] Loss: 0.476470\n",
      "Train Epoch: 1 [3648/7119 (51%)] Loss: 0.454671\n",
      "Train Epoch: 1 [3712/7119 (52%)] Loss: 0.591338\n",
      "Train Epoch: 1 [3776/7119 (53%)] Loss: 0.594868\n",
      "Train Epoch: 1 [3840/7119 (54%)] Loss: 0.298848\n",
      "Train Epoch: 1 [3904/7119 (55%)] Loss: 0.417453\n",
      "Train Epoch: 1 [3968/7119 (56%)] Loss: 0.485184\n",
      "Train Epoch: 1 [4032/7119 (57%)] Loss: 0.417000\n",
      "Train Epoch: 1 [4096/7119 (58%)] Loss: 0.236279\n",
      "Train Epoch: 1 [4160/7119 (58%)] Loss: 0.424536\n",
      "Train Epoch: 1 [4224/7119 (59%)] Loss: 0.487412\n",
      "Train Epoch: 1 [4288/7119 (60%)] Loss: 0.253499\n",
      "Train Epoch: 1 [4352/7119 (61%)] Loss: 0.482727\n",
      "Train Epoch: 1 [4416/7119 (62%)] Loss: 0.350794\n",
      "Train Epoch: 1 [4480/7119 (63%)] Loss: 0.429210\n",
      "Train Epoch: 1 [4544/7119 (64%)] Loss: 0.499926\n",
      "Train Epoch: 1 [4608/7119 (65%)] Loss: 0.623945\n",
      "Train Epoch: 1 [4672/7119 (66%)] Loss: 0.607605\n",
      "Train Epoch: 1 [4736/7119 (67%)] Loss: 0.825193\n",
      "Train Epoch: 1 [4800/7119 (67%)] Loss: 0.386921\n",
      "Train Epoch: 1 [4864/7119 (68%)] Loss: 0.277137\n",
      "Train Epoch: 1 [4928/7119 (69%)] Loss: 0.265647\n",
      "Train Epoch: 1 [4992/7119 (70%)] Loss: 0.442459\n",
      "Train Epoch: 1 [5056/7119 (71%)] Loss: 0.803536\n",
      "Train Epoch: 1 [5120/7119 (72%)] Loss: 0.267488\n",
      "Train Epoch: 1 [5184/7119 (73%)] Loss: 0.303651\n",
      "Train Epoch: 1 [5248/7119 (74%)] Loss: 0.345994\n",
      "Train Epoch: 1 [5312/7119 (75%)] Loss: 0.384292\n",
      "Train Epoch: 1 [5376/7119 (76%)] Loss: 0.562751\n",
      "Train Epoch: 1 [5440/7119 (76%)] Loss: 0.312356\n",
      "Train Epoch: 1 [5504/7119 (77%)] Loss: 0.391788\n",
      "Train Epoch: 1 [5568/7119 (78%)] Loss: 0.332752\n",
      "Train Epoch: 1 [5632/7119 (79%)] Loss: 0.515486\n",
      "Train Epoch: 1 [5696/7119 (80%)] Loss: 0.357223\n",
      "Train Epoch: 1 [5760/7119 (81%)] Loss: 0.249187\n",
      "Train Epoch: 1 [5824/7119 (82%)] Loss: 0.415177\n",
      "Train Epoch: 1 [5888/7119 (83%)] Loss: 0.338674\n",
      "Train Epoch: 1 [5952/7119 (84%)] Loss: 0.366138\n",
      "Train Epoch: 1 [6016/7119 (85%)] Loss: 0.500699\n",
      "Train Epoch: 1 [6080/7119 (85%)] Loss: 0.467301\n",
      "Train Epoch: 1 [6144/7119 (86%)] Loss: 0.140913\n",
      "Train Epoch: 1 [6208/7119 (87%)] Loss: 0.170844\n",
      "Train Epoch: 1 [6272/7119 (88%)] Loss: 0.349582\n",
      "Train Epoch: 1 [6336/7119 (89%)] Loss: 0.393708\n",
      "Train Epoch: 1 [6400/7119 (90%)] Loss: 0.652336\n",
      "Train Epoch: 1 [6464/7119 (91%)] Loss: 0.360053\n",
      "Train Epoch: 1 [6528/7119 (92%)] Loss: 0.333565\n",
      "Train Epoch: 1 [6592/7119 (93%)] Loss: 0.280909\n",
      "Train Epoch: 1 [6656/7119 (93%)] Loss: 0.278071\n",
      "Train Epoch: 1 [6720/7119 (94%)] Loss: 0.486485\n",
      "Train Epoch: 1 [6784/7119 (95%)] Loss: 0.410048\n",
      "Train Epoch: 1 [6848/7119 (96%)] Loss: 0.331191\n",
      "Train Epoch: 1 [6912/7119 (97%)] Loss: 0.562774\n",
      "Train Epoch: 1 [6976/7119 (98%)] Loss: 0.339966\n",
      "Train Epoch: 1 [7040/7119 (99%)] Loss: 0.344455\n",
      "Train Epoch: 1 [7104/7119 (100%)] Loss: 0.142949\n",
      "    epoch          : 1\n",
      "    loss           : 0.43284510544846566\n",
      "    accuracy       : 0.8060393258426967\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.3085411013662815\n",
      "    val_accuracy   : 0.8754166666666667\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch1.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 2 [0/7119 (0%)] Loss: 0.410486\n",
      "Train Epoch: 2 [64/7119 (1%)] Loss: 0.352428\n",
      "Train Epoch: 2 [128/7119 (2%)] Loss: 0.412020\n",
      "Train Epoch: 2 [192/7119 (3%)] Loss: 0.218336\n",
      "Train Epoch: 2 [256/7119 (4%)] Loss: 0.404532\n",
      "Train Epoch: 2 [320/7119 (4%)] Loss: 0.760982\n",
      "Train Epoch: 2 [384/7119 (5%)] Loss: 0.293771\n",
      "Train Epoch: 2 [448/7119 (6%)] Loss: 0.437342\n",
      "Train Epoch: 2 [512/7119 (7%)] Loss: 0.349218\n",
      "Train Epoch: 2 [576/7119 (8%)] Loss: 0.290555\n",
      "Train Epoch: 2 [640/7119 (9%)] Loss: 0.206461\n",
      "Train Epoch: 2 [704/7119 (10%)] Loss: 0.361698\n",
      "Train Epoch: 2 [768/7119 (11%)] Loss: 0.480058\n",
      "Train Epoch: 2 [832/7119 (12%)] Loss: 0.205771\n",
      "Train Epoch: 2 [896/7119 (13%)] Loss: 0.187012\n",
      "Train Epoch: 2 [960/7119 (13%)] Loss: 0.213999\n",
      "Train Epoch: 2 [1024/7119 (14%)] Loss: 0.255312\n",
      "Train Epoch: 2 [1088/7119 (15%)] Loss: 0.308165\n",
      "Train Epoch: 2 [1152/7119 (16%)] Loss: 0.200657\n",
      "Train Epoch: 2 [1216/7119 (17%)] Loss: 0.373417\n",
      "Train Epoch: 2 [1280/7119 (18%)] Loss: 0.413591\n",
      "Train Epoch: 2 [1344/7119 (19%)] Loss: 0.479580\n",
      "Train Epoch: 2 [1408/7119 (20%)] Loss: 0.187206\n",
      "Train Epoch: 2 [1472/7119 (21%)] Loss: 0.596385\n",
      "Train Epoch: 2 [1536/7119 (22%)] Loss: 0.155435\n",
      "Train Epoch: 2 [1600/7119 (22%)] Loss: 0.182516\n",
      "Train Epoch: 2 [1664/7119 (23%)] Loss: 0.368822\n",
      "Train Epoch: 2 [1728/7119 (24%)] Loss: 0.386172\n",
      "Train Epoch: 2 [1792/7119 (25%)] Loss: 0.387661\n",
      "Train Epoch: 2 [1856/7119 (26%)] Loss: 0.457141\n",
      "Train Epoch: 2 [1920/7119 (27%)] Loss: 0.384844\n",
      "Train Epoch: 2 [1984/7119 (28%)] Loss: 0.308682\n",
      "Train Epoch: 2 [2048/7119 (29%)] Loss: 0.266394\n",
      "Train Epoch: 2 [2112/7119 (30%)] Loss: 0.306201\n",
      "Train Epoch: 2 [2176/7119 (31%)] Loss: 0.270315\n",
      "Train Epoch: 2 [2240/7119 (31%)] Loss: 0.326762\n",
      "Train Epoch: 2 [2304/7119 (32%)] Loss: 0.243486\n",
      "Train Epoch: 2 [2368/7119 (33%)] Loss: 0.229265\n",
      "Train Epoch: 2 [2432/7119 (34%)] Loss: 0.313699\n",
      "Train Epoch: 2 [2496/7119 (35%)] Loss: 0.232528\n",
      "Train Epoch: 2 [2560/7119 (36%)] Loss: 0.299304\n",
      "Train Epoch: 2 [2624/7119 (37%)] Loss: 0.528221\n",
      "Train Epoch: 2 [2688/7119 (38%)] Loss: 0.187289\n",
      "Train Epoch: 2 [2752/7119 (39%)] Loss: 0.988804\n",
      "Train Epoch: 2 [2816/7119 (40%)] Loss: 0.135903\n",
      "Train Epoch: 2 [2880/7119 (40%)] Loss: 0.313033\n",
      "Train Epoch: 2 [2944/7119 (41%)] Loss: 0.269435\n",
      "Train Epoch: 2 [3008/7119 (42%)] Loss: 0.461209\n",
      "Train Epoch: 2 [3072/7119 (43%)] Loss: 0.297597\n",
      "Train Epoch: 2 [3136/7119 (44%)] Loss: 0.104436\n",
      "Train Epoch: 2 [3200/7119 (45%)] Loss: 0.219016\n",
      "Train Epoch: 2 [3264/7119 (46%)] Loss: 0.281366\n",
      "Train Epoch: 2 [3328/7119 (47%)] Loss: 0.238889\n",
      "Train Epoch: 2 [3392/7119 (48%)] Loss: 0.689923\n",
      "Train Epoch: 2 [3456/7119 (49%)] Loss: 0.184700\n",
      "Train Epoch: 2 [3520/7119 (49%)] Loss: 0.411881\n",
      "Train Epoch: 2 [3584/7119 (50%)] Loss: 0.369337\n",
      "Train Epoch: 2 [3648/7119 (51%)] Loss: 0.524159\n",
      "Train Epoch: 2 [3712/7119 (52%)] Loss: 0.386050\n",
      "Train Epoch: 2 [3776/7119 (53%)] Loss: 0.364266\n",
      "Train Epoch: 2 [3840/7119 (54%)] Loss: 0.601330\n",
      "Train Epoch: 2 [3904/7119 (55%)] Loss: 0.553564\n",
      "Train Epoch: 2 [3968/7119 (56%)] Loss: 0.236029\n",
      "Train Epoch: 2 [4032/7119 (57%)] Loss: 0.539212\n",
      "Train Epoch: 2 [4096/7119 (58%)] Loss: 0.343810\n",
      "Train Epoch: 2 [4160/7119 (58%)] Loss: 0.269393\n",
      "Train Epoch: 2 [4224/7119 (59%)] Loss: 0.280649\n",
      "Train Epoch: 2 [4288/7119 (60%)] Loss: 0.113907\n",
      "Train Epoch: 2 [4352/7119 (61%)] Loss: 0.239192\n",
      "Train Epoch: 2 [4416/7119 (62%)] Loss: 0.427465\n",
      "Train Epoch: 2 [4480/7119 (63%)] Loss: 0.255776\n",
      "Train Epoch: 2 [4544/7119 (64%)] Loss: 0.440998\n",
      "Train Epoch: 2 [4608/7119 (65%)] Loss: 0.464531\n",
      "Train Epoch: 2 [4672/7119 (66%)] Loss: 0.444444\n",
      "Train Epoch: 2 [4736/7119 (67%)] Loss: 0.189458\n",
      "Train Epoch: 2 [4800/7119 (67%)] Loss: 0.518454\n",
      "Train Epoch: 2 [4864/7119 (68%)] Loss: 0.895084\n",
      "Train Epoch: 2 [4928/7119 (69%)] Loss: 0.386155\n",
      "Train Epoch: 2 [4992/7119 (70%)] Loss: 0.714566\n",
      "Train Epoch: 2 [5056/7119 (71%)] Loss: 0.328446\n",
      "Train Epoch: 2 [5120/7119 (72%)] Loss: 0.305877\n",
      "Train Epoch: 2 [5184/7119 (73%)] Loss: 0.371061\n",
      "Train Epoch: 2 [5248/7119 (74%)] Loss: 0.477846\n",
      "Train Epoch: 2 [5312/7119 (75%)] Loss: 0.545126\n",
      "Train Epoch: 2 [5376/7119 (76%)] Loss: 0.306327\n",
      "Train Epoch: 2 [5440/7119 (76%)] Loss: 0.524059\n",
      "Train Epoch: 2 [5504/7119 (77%)] Loss: 0.523251\n",
      "Train Epoch: 2 [5568/7119 (78%)] Loss: 0.683326\n",
      "Train Epoch: 2 [5632/7119 (79%)] Loss: 0.297519\n",
      "Train Epoch: 2 [5696/7119 (80%)] Loss: 0.422019\n",
      "Train Epoch: 2 [5760/7119 (81%)] Loss: 0.208381\n",
      "Train Epoch: 2 [5824/7119 (82%)] Loss: 0.168005\n",
      "Train Epoch: 2 [5888/7119 (83%)] Loss: 0.390628\n",
      "Train Epoch: 2 [5952/7119 (84%)] Loss: 0.375569\n",
      "Train Epoch: 2 [6016/7119 (85%)] Loss: 0.467735\n",
      "Train Epoch: 2 [6080/7119 (85%)] Loss: 0.574796\n",
      "Train Epoch: 2 [6144/7119 (86%)] Loss: 0.248917\n",
      "Train Epoch: 2 [6208/7119 (87%)] Loss: 0.289409\n",
      "Train Epoch: 2 [6272/7119 (88%)] Loss: 0.359145\n",
      "Train Epoch: 2 [6336/7119 (89%)] Loss: 0.119393\n",
      "Train Epoch: 2 [6400/7119 (90%)] Loss: 0.292243\n",
      "Train Epoch: 2 [6464/7119 (91%)] Loss: 0.366455\n",
      "Train Epoch: 2 [6528/7119 (92%)] Loss: 0.209072\n",
      "Train Epoch: 2 [6592/7119 (93%)] Loss: 0.420012\n",
      "Train Epoch: 2 [6656/7119 (93%)] Loss: 0.268527\n",
      "Train Epoch: 2 [6720/7119 (94%)] Loss: 0.280909\n",
      "Train Epoch: 2 [6784/7119 (95%)] Loss: 0.442514\n",
      "Train Epoch: 2 [6848/7119 (96%)] Loss: 0.192303\n",
      "Train Epoch: 2 [6912/7119 (97%)] Loss: 0.351538\n",
      "Train Epoch: 2 [6976/7119 (98%)] Loss: 0.270773\n",
      "Train Epoch: 2 [7040/7119 (99%)] Loss: 0.298768\n",
      "Train Epoch: 2 [7104/7119 (100%)] Loss: 0.315411\n",
      "    epoch          : 2\n",
      "    loss           : 0.3624998132666845\n",
      "    accuracy       : 0.8483052434456929\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.2898856829106808\n",
      "    val_accuracy   : 0.88625\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch2.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 3 [0/7119 (0%)] Loss: 0.284784\n",
      "Train Epoch: 3 [64/7119 (1%)] Loss: 0.129861\n",
      "Train Epoch: 3 [128/7119 (2%)] Loss: 0.482543\n",
      "Train Epoch: 3 [192/7119 (3%)] Loss: 0.351347\n",
      "Train Epoch: 3 [256/7119 (4%)] Loss: 0.354154\n",
      "Train Epoch: 3 [320/7119 (4%)] Loss: 0.403245\n",
      "Train Epoch: 3 [384/7119 (5%)] Loss: 0.248485\n",
      "Train Epoch: 3 [448/7119 (6%)] Loss: 0.410725\n",
      "Train Epoch: 3 [512/7119 (7%)] Loss: 0.210933\n",
      "Train Epoch: 3 [576/7119 (8%)] Loss: 0.614681\n",
      "Train Epoch: 3 [640/7119 (9%)] Loss: 0.648052\n",
      "Train Epoch: 3 [704/7119 (10%)] Loss: 0.600701\n",
      "Train Epoch: 3 [768/7119 (11%)] Loss: 0.338940\n",
      "Train Epoch: 3 [832/7119 (12%)] Loss: 0.435684\n",
      "Train Epoch: 3 [896/7119 (13%)] Loss: 0.235327\n",
      "Train Epoch: 3 [960/7119 (13%)] Loss: 0.391133\n",
      "Train Epoch: 3 [1024/7119 (14%)] Loss: 0.415266\n",
      "Train Epoch: 3 [1088/7119 (15%)] Loss: 0.697419\n",
      "Train Epoch: 3 [1152/7119 (16%)] Loss: 0.667142\n",
      "Train Epoch: 3 [1216/7119 (17%)] Loss: 0.221213\n",
      "Train Epoch: 3 [1280/7119 (18%)] Loss: 0.299335\n",
      "Train Epoch: 3 [1344/7119 (19%)] Loss: 0.210617\n",
      "Train Epoch: 3 [1408/7119 (20%)] Loss: 0.554453\n",
      "Train Epoch: 3 [1472/7119 (21%)] Loss: 0.438043\n",
      "Train Epoch: 3 [1536/7119 (22%)] Loss: 0.255107\n",
      "Train Epoch: 3 [1600/7119 (22%)] Loss: 0.269012\n",
      "Train Epoch: 3 [1664/7119 (23%)] Loss: 0.667183\n",
      "Train Epoch: 3 [1728/7119 (24%)] Loss: 0.515557\n",
      "Train Epoch: 3 [1792/7119 (25%)] Loss: 0.102990\n",
      "Train Epoch: 3 [1856/7119 (26%)] Loss: 0.599001\n",
      "Train Epoch: 3 [1920/7119 (27%)] Loss: 0.583465\n",
      "Train Epoch: 3 [1984/7119 (28%)] Loss: 0.544663\n",
      "Train Epoch: 3 [2048/7119 (29%)] Loss: 0.180888\n",
      "Train Epoch: 3 [2112/7119 (30%)] Loss: 0.210454\n",
      "Train Epoch: 3 [2176/7119 (31%)] Loss: 0.335188\n",
      "Train Epoch: 3 [2240/7119 (31%)] Loss: 0.349370\n",
      "Train Epoch: 3 [2304/7119 (32%)] Loss: 1.010510\n",
      "Train Epoch: 3 [2368/7119 (33%)] Loss: 0.205330\n",
      "Train Epoch: 3 [2432/7119 (34%)] Loss: 0.216910\n",
      "Train Epoch: 3 [2496/7119 (35%)] Loss: 0.372795\n",
      "Train Epoch: 3 [2560/7119 (36%)] Loss: 0.388179\n",
      "Train Epoch: 3 [2624/7119 (37%)] Loss: 0.237103\n",
      "Train Epoch: 3 [2688/7119 (38%)] Loss: 0.617955\n",
      "Train Epoch: 3 [2752/7119 (39%)] Loss: 0.327575\n",
      "Train Epoch: 3 [2816/7119 (40%)] Loss: 0.328462\n",
      "Train Epoch: 3 [2880/7119 (40%)] Loss: 0.270528\n",
      "Train Epoch: 3 [2944/7119 (41%)] Loss: 0.332923\n",
      "Train Epoch: 3 [3008/7119 (42%)] Loss: 0.433202\n",
      "Train Epoch: 3 [3072/7119 (43%)] Loss: 0.500006\n",
      "Train Epoch: 3 [3136/7119 (44%)] Loss: 0.291278\n",
      "Train Epoch: 3 [3200/7119 (45%)] Loss: 0.375111\n",
      "Train Epoch: 3 [3264/7119 (46%)] Loss: 0.449613\n",
      "Train Epoch: 3 [3328/7119 (47%)] Loss: 0.430644\n",
      "Train Epoch: 3 [3392/7119 (48%)] Loss: 0.554823\n",
      "Train Epoch: 3 [3456/7119 (49%)] Loss: 0.166730\n",
      "Train Epoch: 3 [3520/7119 (49%)] Loss: 0.438822\n",
      "Train Epoch: 3 [3584/7119 (50%)] Loss: 0.133444\n",
      "Train Epoch: 3 [3648/7119 (51%)] Loss: 0.188751\n",
      "Train Epoch: 3 [3712/7119 (52%)] Loss: 0.367177\n",
      "Train Epoch: 3 [3776/7119 (53%)] Loss: 0.227361\n",
      "Train Epoch: 3 [3840/7119 (54%)] Loss: 0.188379\n",
      "Train Epoch: 3 [3904/7119 (55%)] Loss: 0.310074\n",
      "Train Epoch: 3 [3968/7119 (56%)] Loss: 0.325987\n",
      "Train Epoch: 3 [4032/7119 (57%)] Loss: 0.341536\n",
      "Train Epoch: 3 [4096/7119 (58%)] Loss: 0.464608\n",
      "Train Epoch: 3 [4160/7119 (58%)] Loss: 0.404635\n",
      "Train Epoch: 3 [4224/7119 (59%)] Loss: 0.338413\n",
      "Train Epoch: 3 [4288/7119 (60%)] Loss: 0.255546\n",
      "Train Epoch: 3 [4352/7119 (61%)] Loss: 0.478171\n",
      "Train Epoch: 3 [4416/7119 (62%)] Loss: 0.255566\n",
      "Train Epoch: 3 [4480/7119 (63%)] Loss: 0.260997\n",
      "Train Epoch: 3 [4544/7119 (64%)] Loss: 0.335666\n",
      "Train Epoch: 3 [4608/7119 (65%)] Loss: 0.227511\n",
      "Train Epoch: 3 [4672/7119 (66%)] Loss: 0.339289\n",
      "Train Epoch: 3 [4736/7119 (67%)] Loss: 0.289876\n",
      "Train Epoch: 3 [4800/7119 (67%)] Loss: 0.704056\n",
      "Train Epoch: 3 [4864/7119 (68%)] Loss: 0.138730\n",
      "Train Epoch: 3 [4928/7119 (69%)] Loss: 0.525962\n",
      "Train Epoch: 3 [4992/7119 (70%)] Loss: 0.313115\n",
      "Train Epoch: 3 [5056/7119 (71%)] Loss: 0.347399\n",
      "Train Epoch: 3 [5120/7119 (72%)] Loss: 0.407497\n",
      "Train Epoch: 3 [5184/7119 (73%)] Loss: 0.327460\n",
      "Train Epoch: 3 [5248/7119 (74%)] Loss: 0.551471\n",
      "Train Epoch: 3 [5312/7119 (75%)] Loss: 0.259649\n",
      "Train Epoch: 3 [5376/7119 (76%)] Loss: 0.303670\n",
      "Train Epoch: 3 [5440/7119 (76%)] Loss: 0.342136\n",
      "Train Epoch: 3 [5504/7119 (77%)] Loss: 0.218984\n",
      "Train Epoch: 3 [5568/7119 (78%)] Loss: 0.309751\n",
      "Train Epoch: 3 [5632/7119 (79%)] Loss: 0.173212\n",
      "Train Epoch: 3 [5696/7119 (80%)] Loss: 0.210483\n",
      "Train Epoch: 3 [5760/7119 (81%)] Loss: 0.271088\n",
      "Train Epoch: 3 [5824/7119 (82%)] Loss: 0.350343\n",
      "Train Epoch: 3 [5888/7119 (83%)] Loss: 0.106254\n",
      "Train Epoch: 3 [5952/7119 (84%)] Loss: 0.291072\n",
      "Train Epoch: 3 [6016/7119 (85%)] Loss: 0.279579\n",
      "Train Epoch: 3 [6080/7119 (85%)] Loss: 0.619694\n",
      "Train Epoch: 3 [6144/7119 (86%)] Loss: 0.264457\n",
      "Train Epoch: 3 [6208/7119 (87%)] Loss: 0.373316\n",
      "Train Epoch: 3 [6272/7119 (88%)] Loss: 0.182852\n",
      "Train Epoch: 3 [6336/7119 (89%)] Loss: 0.177443\n",
      "Train Epoch: 3 [6400/7119 (90%)] Loss: 0.272630\n",
      "Train Epoch: 3 [6464/7119 (91%)] Loss: 0.267604\n",
      "Train Epoch: 3 [6528/7119 (92%)] Loss: 0.474958\n",
      "Train Epoch: 3 [6592/7119 (93%)] Loss: 0.375358\n",
      "Train Epoch: 3 [6656/7119 (93%)] Loss: 0.204597\n",
      "Train Epoch: 3 [6720/7119 (94%)] Loss: 0.218207\n",
      "Train Epoch: 3 [6784/7119 (95%)] Loss: 0.225777\n",
      "Train Epoch: 3 [6848/7119 (96%)] Loss: 0.254478\n",
      "Train Epoch: 3 [6912/7119 (97%)] Loss: 0.191163\n",
      "Train Epoch: 3 [6976/7119 (98%)] Loss: 0.531525\n",
      "Train Epoch: 3 [7040/7119 (99%)] Loss: 0.362517\n",
      "Train Epoch: 3 [7104/7119 (100%)] Loss: 0.251051\n",
      "    epoch          : 3\n",
      "    loss           : 0.35242104212219794\n",
      "    accuracy       : 0.8485861423220974\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.3333857491612434\n",
      "    val_accuracy   : 0.8525\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch3.pth ...\n",
      "Train Epoch: 4 [0/7119 (0%)] Loss: 0.989134\n",
      "Train Epoch: 4 [64/7119 (1%)] Loss: 0.270150\n",
      "Train Epoch: 4 [128/7119 (2%)] Loss: 0.188908\n",
      "Train Epoch: 4 [192/7119 (3%)] Loss: 0.108827\n",
      "Train Epoch: 4 [256/7119 (4%)] Loss: 0.125774\n",
      "Train Epoch: 4 [320/7119 (4%)] Loss: 0.216034\n",
      "Train Epoch: 4 [384/7119 (5%)] Loss: 0.437102\n",
      "Train Epoch: 4 [448/7119 (6%)] Loss: 0.328501\n",
      "Train Epoch: 4 [512/7119 (7%)] Loss: 0.205792\n",
      "Train Epoch: 4 [576/7119 (8%)] Loss: 0.446749\n",
      "Train Epoch: 4 [640/7119 (9%)] Loss: 0.551055\n",
      "Train Epoch: 4 [704/7119 (10%)] Loss: 0.242197\n",
      "Train Epoch: 4 [768/7119 (11%)] Loss: 0.618383\n",
      "Train Epoch: 4 [832/7119 (12%)] Loss: 0.620590\n",
      "Train Epoch: 4 [896/7119 (13%)] Loss: 0.575319\n",
      "Train Epoch: 4 [960/7119 (13%)] Loss: 0.545898\n",
      "Train Epoch: 4 [1024/7119 (14%)] Loss: 0.424363\n",
      "Train Epoch: 4 [1088/7119 (15%)] Loss: 0.475682\n",
      "Train Epoch: 4 [1152/7119 (16%)] Loss: 0.176382\n",
      "Train Epoch: 4 [1216/7119 (17%)] Loss: 0.207404\n",
      "Train Epoch: 4 [1280/7119 (18%)] Loss: 0.234312\n",
      "Train Epoch: 4 [1344/7119 (19%)] Loss: 0.116252\n",
      "Train Epoch: 4 [1408/7119 (20%)] Loss: 0.382978\n",
      "Train Epoch: 4 [1472/7119 (21%)] Loss: 0.617367\n",
      "Train Epoch: 4 [1536/7119 (22%)] Loss: 0.875837\n",
      "Train Epoch: 4 [1600/7119 (22%)] Loss: 0.253985\n",
      "Train Epoch: 4 [1664/7119 (23%)] Loss: 0.519694\n",
      "Train Epoch: 4 [1728/7119 (24%)] Loss: 0.145230\n",
      "Train Epoch: 4 [1792/7119 (25%)] Loss: 0.323474\n",
      "Train Epoch: 4 [1856/7119 (26%)] Loss: 0.497957\n",
      "Train Epoch: 4 [1920/7119 (27%)] Loss: 0.271232\n",
      "Train Epoch: 4 [1984/7119 (28%)] Loss: 0.429011\n",
      "Train Epoch: 4 [2048/7119 (29%)] Loss: 0.137762\n",
      "Train Epoch: 4 [2112/7119 (30%)] Loss: 0.203969\n",
      "Train Epoch: 4 [2176/7119 (31%)] Loss: 0.520412\n",
      "Train Epoch: 4 [2240/7119 (31%)] Loss: 0.465818\n",
      "Train Epoch: 4 [2304/7119 (32%)] Loss: 0.166686\n",
      "Train Epoch: 4 [2368/7119 (33%)] Loss: 0.491319\n",
      "Train Epoch: 4 [2432/7119 (34%)] Loss: 0.326832\n",
      "Train Epoch: 4 [2496/7119 (35%)] Loss: 0.284490\n",
      "Train Epoch: 4 [2560/7119 (36%)] Loss: 0.250120\n",
      "Train Epoch: 4 [2624/7119 (37%)] Loss: 0.205286\n",
      "Train Epoch: 4 [2688/7119 (38%)] Loss: 0.385673\n",
      "Train Epoch: 4 [2752/7119 (39%)] Loss: 0.183830\n",
      "Train Epoch: 4 [2816/7119 (40%)] Loss: 0.462458\n",
      "Train Epoch: 4 [2880/7119 (40%)] Loss: 0.572234\n",
      "Train Epoch: 4 [2944/7119 (41%)] Loss: 0.200172\n",
      "Train Epoch: 4 [3008/7119 (42%)] Loss: 0.264628\n",
      "Train Epoch: 4 [3072/7119 (43%)] Loss: 0.341168\n",
      "Train Epoch: 4 [3136/7119 (44%)] Loss: 0.271802\n",
      "Train Epoch: 4 [3200/7119 (45%)] Loss: 0.157800\n",
      "Train Epoch: 4 [3264/7119 (46%)] Loss: 0.173226\n",
      "Train Epoch: 4 [3328/7119 (47%)] Loss: 0.258934\n",
      "Train Epoch: 4 [3392/7119 (48%)] Loss: 0.636106\n",
      "Train Epoch: 4 [3456/7119 (49%)] Loss: 0.289085\n",
      "Train Epoch: 4 [3520/7119 (49%)] Loss: 0.368968\n",
      "Train Epoch: 4 [3584/7119 (50%)] Loss: 0.356663\n",
      "Train Epoch: 4 [3648/7119 (51%)] Loss: 0.372159\n",
      "Train Epoch: 4 [3712/7119 (52%)] Loss: 0.171283\n",
      "Train Epoch: 4 [3776/7119 (53%)] Loss: 0.175310\n",
      "Train Epoch: 4 [3840/7119 (54%)] Loss: 0.164003\n",
      "Train Epoch: 4 [3904/7119 (55%)] Loss: 0.271120\n",
      "Train Epoch: 4 [3968/7119 (56%)] Loss: 0.318140\n",
      "Train Epoch: 4 [4032/7119 (57%)] Loss: 0.599120\n",
      "Train Epoch: 4 [4096/7119 (58%)] Loss: 0.423780\n",
      "Train Epoch: 4 [4160/7119 (58%)] Loss: 0.418155\n",
      "Train Epoch: 4 [4224/7119 (59%)] Loss: 0.595603\n",
      "Train Epoch: 4 [4288/7119 (60%)] Loss: 0.263854\n",
      "Train Epoch: 4 [4352/7119 (61%)] Loss: 0.619319\n",
      "Train Epoch: 4 [4416/7119 (62%)] Loss: 0.399974\n",
      "Train Epoch: 4 [4480/7119 (63%)] Loss: 0.354975\n",
      "Train Epoch: 4 [4544/7119 (64%)] Loss: 0.470661\n",
      "Train Epoch: 4 [4608/7119 (65%)] Loss: 0.289189\n",
      "Train Epoch: 4 [4672/7119 (66%)] Loss: 0.218875\n",
      "Train Epoch: 4 [4736/7119 (67%)] Loss: 0.384824\n",
      "Train Epoch: 4 [4800/7119 (67%)] Loss: 0.171340\n",
      "Train Epoch: 4 [4864/7119 (68%)] Loss: 0.451953\n",
      "Train Epoch: 4 [4928/7119 (69%)] Loss: 0.309439\n",
      "Train Epoch: 4 [4992/7119 (70%)] Loss: 0.235922\n",
      "Train Epoch: 4 [5056/7119 (71%)] Loss: 0.511862\n",
      "Train Epoch: 4 [5120/7119 (72%)] Loss: 0.252318\n",
      "Train Epoch: 4 [5184/7119 (73%)] Loss: 0.444211\n",
      "Train Epoch: 4 [5248/7119 (74%)] Loss: 0.266675\n",
      "Train Epoch: 4 [5312/7119 (75%)] Loss: 0.412837\n",
      "Train Epoch: 4 [5376/7119 (76%)] Loss: 0.375571\n",
      "Train Epoch: 4 [5440/7119 (76%)] Loss: 0.293791\n",
      "Train Epoch: 4 [5504/7119 (77%)] Loss: 0.549182\n",
      "Train Epoch: 4 [5568/7119 (78%)] Loss: 0.521871\n",
      "Train Epoch: 4 [5632/7119 (79%)] Loss: 0.317381\n",
      "Train Epoch: 4 [5696/7119 (80%)] Loss: 0.268670\n",
      "Train Epoch: 4 [5760/7119 (81%)] Loss: 0.138761\n",
      "Train Epoch: 4 [5824/7119 (82%)] Loss: 0.732794\n",
      "Train Epoch: 4 [5888/7119 (83%)] Loss: 0.385726\n",
      "Train Epoch: 4 [5952/7119 (84%)] Loss: 0.586303\n",
      "Train Epoch: 4 [6016/7119 (85%)] Loss: 0.176226\n",
      "Train Epoch: 4 [6080/7119 (85%)] Loss: 0.247596\n",
      "Train Epoch: 4 [6144/7119 (86%)] Loss: 0.458712\n",
      "Train Epoch: 4 [6208/7119 (87%)] Loss: 0.476320\n",
      "Train Epoch: 4 [6272/7119 (88%)] Loss: 0.359754\n",
      "Train Epoch: 4 [6336/7119 (89%)] Loss: 0.537162\n",
      "Train Epoch: 4 [6400/7119 (90%)] Loss: 0.742773\n",
      "Train Epoch: 4 [6464/7119 (91%)] Loss: 0.434189\n",
      "Train Epoch: 4 [6528/7119 (92%)] Loss: 0.234560\n",
      "Train Epoch: 4 [6592/7119 (93%)] Loss: 0.578206\n",
      "Train Epoch: 4 [6656/7119 (93%)] Loss: 0.409044\n",
      "Train Epoch: 4 [6720/7119 (94%)] Loss: 0.360182\n",
      "Train Epoch: 4 [6784/7119 (95%)] Loss: 0.167906\n",
      "Train Epoch: 4 [6848/7119 (96%)] Loss: 0.421843\n",
      "Train Epoch: 4 [6912/7119 (97%)] Loss: 0.074130\n",
      "Train Epoch: 4 [6976/7119 (98%)] Loss: 0.303066\n",
      "Train Epoch: 4 [7040/7119 (99%)] Loss: 0.281206\n",
      "Train Epoch: 4 [7104/7119 (100%)] Loss: 0.366860\n",
      "    epoch          : 4\n",
      "    loss           : 0.3386287133680301\n",
      "    accuracy       : 0.8577059925093633\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.25955019921064376\n",
      "    val_accuracy   : 0.9079166666666667\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch4.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 5 [0/7119 (0%)] Loss: 0.341542\n",
      "Train Epoch: 5 [64/7119 (1%)] Loss: 0.112325\n",
      "Train Epoch: 5 [128/7119 (2%)] Loss: 0.603780\n",
      "Train Epoch: 5 [192/7119 (3%)] Loss: 0.582562\n",
      "Train Epoch: 5 [256/7119 (4%)] Loss: 0.202067\n",
      "Train Epoch: 5 [320/7119 (4%)] Loss: 0.120398\n",
      "Train Epoch: 5 [384/7119 (5%)] Loss: 0.113478\n",
      "Train Epoch: 5 [448/7119 (6%)] Loss: 0.115557\n",
      "Train Epoch: 5 [512/7119 (7%)] Loss: 0.182177\n",
      "Train Epoch: 5 [576/7119 (8%)] Loss: 0.646458\n",
      "Train Epoch: 5 [640/7119 (9%)] Loss: 0.196181\n",
      "Train Epoch: 5 [704/7119 (10%)] Loss: 0.290521\n",
      "Train Epoch: 5 [768/7119 (11%)] Loss: 0.258134\n",
      "Train Epoch: 5 [832/7119 (12%)] Loss: 0.666409\n",
      "Train Epoch: 5 [896/7119 (13%)] Loss: 0.290004\n",
      "Train Epoch: 5 [960/7119 (13%)] Loss: 0.354890\n",
      "Train Epoch: 5 [1024/7119 (14%)] Loss: 0.365974\n",
      "Train Epoch: 5 [1088/7119 (15%)] Loss: 0.299823\n",
      "Train Epoch: 5 [1152/7119 (16%)] Loss: 0.218848\n",
      "Train Epoch: 5 [1216/7119 (17%)] Loss: 0.194277\n",
      "Train Epoch: 5 [1280/7119 (18%)] Loss: 0.306860\n",
      "Train Epoch: 5 [1344/7119 (19%)] Loss: 0.340153\n",
      "Train Epoch: 5 [1408/7119 (20%)] Loss: 0.465606\n",
      "Train Epoch: 5 [1472/7119 (21%)] Loss: 0.280298\n",
      "Train Epoch: 5 [1536/7119 (22%)] Loss: 0.646894\n",
      "Train Epoch: 5 [1600/7119 (22%)] Loss: 0.592562\n",
      "Train Epoch: 5 [1664/7119 (23%)] Loss: 0.590984\n",
      "Train Epoch: 5 [1728/7119 (24%)] Loss: 0.253362\n",
      "Train Epoch: 5 [1792/7119 (25%)] Loss: 0.277793\n",
      "Train Epoch: 5 [1856/7119 (26%)] Loss: 0.282528\n",
      "Train Epoch: 5 [1920/7119 (27%)] Loss: 0.320367\n",
      "Train Epoch: 5 [1984/7119 (28%)] Loss: 0.663540\n",
      "Train Epoch: 5 [2048/7119 (29%)] Loss: 0.100080\n",
      "Train Epoch: 5 [2112/7119 (30%)] Loss: 0.399841\n",
      "Train Epoch: 5 [2176/7119 (31%)] Loss: 0.381096\n",
      "Train Epoch: 5 [2240/7119 (31%)] Loss: 0.435687\n",
      "Train Epoch: 5 [2304/7119 (32%)] Loss: 0.211812\n",
      "Train Epoch: 5 [2368/7119 (33%)] Loss: 0.447478\n",
      "Train Epoch: 5 [2432/7119 (34%)] Loss: 0.561554\n",
      "Train Epoch: 5 [2496/7119 (35%)] Loss: 0.471493\n",
      "Train Epoch: 5 [2560/7119 (36%)] Loss: 0.625543\n",
      "Train Epoch: 5 [2624/7119 (37%)] Loss: 0.572633\n",
      "Train Epoch: 5 [2688/7119 (38%)] Loss: 0.296451\n",
      "Train Epoch: 5 [2752/7119 (39%)] Loss: 0.444172\n",
      "Train Epoch: 5 [2816/7119 (40%)] Loss: 0.099533\n",
      "Train Epoch: 5 [2880/7119 (40%)] Loss: 0.123119\n",
      "Train Epoch: 5 [2944/7119 (41%)] Loss: 0.399613\n",
      "Train Epoch: 5 [3008/7119 (42%)] Loss: 0.408206\n",
      "Train Epoch: 5 [3072/7119 (43%)] Loss: 0.373722\n",
      "Train Epoch: 5 [3136/7119 (44%)] Loss: 0.405931\n",
      "Train Epoch: 5 [3200/7119 (45%)] Loss: 0.283042\n",
      "Train Epoch: 5 [3264/7119 (46%)] Loss: 0.181719\n",
      "Train Epoch: 5 [3328/7119 (47%)] Loss: 0.560621\n",
      "Train Epoch: 5 [3392/7119 (48%)] Loss: 0.388589\n",
      "Train Epoch: 5 [3456/7119 (49%)] Loss: 0.341229\n",
      "Train Epoch: 5 [3520/7119 (49%)] Loss: 0.341873\n",
      "Train Epoch: 5 [3584/7119 (50%)] Loss: 0.225507\n",
      "Train Epoch: 5 [3648/7119 (51%)] Loss: 0.403603\n",
      "Train Epoch: 5 [3712/7119 (52%)] Loss: 0.535420\n",
      "Train Epoch: 5 [3776/7119 (53%)] Loss: 0.290098\n",
      "Train Epoch: 5 [3840/7119 (54%)] Loss: 0.190428\n",
      "Train Epoch: 5 [3904/7119 (55%)] Loss: 0.296471\n",
      "Train Epoch: 5 [3968/7119 (56%)] Loss: 0.224293\n",
      "Train Epoch: 5 [4032/7119 (57%)] Loss: 0.389144\n",
      "Train Epoch: 5 [4096/7119 (58%)] Loss: 0.458471\n",
      "Train Epoch: 5 [4160/7119 (58%)] Loss: 0.319902\n",
      "Train Epoch: 5 [4224/7119 (59%)] Loss: 0.212525\n",
      "Train Epoch: 5 [4288/7119 (60%)] Loss: 0.441117\n",
      "Train Epoch: 5 [4352/7119 (61%)] Loss: 0.299642\n",
      "Train Epoch: 5 [4416/7119 (62%)] Loss: 0.471219\n",
      "Train Epoch: 5 [4480/7119 (63%)] Loss: 0.407045\n",
      "Train Epoch: 5 [4544/7119 (64%)] Loss: 0.152711\n",
      "Train Epoch: 5 [4608/7119 (65%)] Loss: 0.448337\n",
      "Train Epoch: 5 [4672/7119 (66%)] Loss: 0.305763\n",
      "Train Epoch: 5 [4736/7119 (67%)] Loss: 0.321044\n",
      "Train Epoch: 5 [4800/7119 (67%)] Loss: 0.189167\n",
      "Train Epoch: 5 [4864/7119 (68%)] Loss: 0.625185\n",
      "Train Epoch: 5 [4928/7119 (69%)] Loss: 0.585057\n",
      "Train Epoch: 5 [4992/7119 (70%)] Loss: 0.821792\n",
      "Train Epoch: 5 [5056/7119 (71%)] Loss: 0.292577\n",
      "Train Epoch: 5 [5120/7119 (72%)] Loss: 0.330820\n",
      "Train Epoch: 5 [5184/7119 (73%)] Loss: 0.190918\n",
      "Train Epoch: 5 [5248/7119 (74%)] Loss: 0.902138\n",
      "Train Epoch: 5 [5312/7119 (75%)] Loss: 0.245144\n",
      "Train Epoch: 5 [5376/7119 (76%)] Loss: 0.543234\n",
      "Train Epoch: 5 [5440/7119 (76%)] Loss: 0.583475\n",
      "Train Epoch: 5 [5504/7119 (77%)] Loss: 0.245221\n",
      "Train Epoch: 5 [5568/7119 (78%)] Loss: 0.174443\n",
      "Train Epoch: 5 [5632/7119 (79%)] Loss: 0.509932\n",
      "Train Epoch: 5 [5696/7119 (80%)] Loss: 0.279076\n",
      "Train Epoch: 5 [5760/7119 (81%)] Loss: 0.452512\n",
      "Train Epoch: 5 [5824/7119 (82%)] Loss: 0.507089\n",
      "Train Epoch: 5 [5888/7119 (83%)] Loss: 0.218603\n",
      "Train Epoch: 5 [5952/7119 (84%)] Loss: 0.714347\n",
      "Train Epoch: 5 [6016/7119 (85%)] Loss: 0.237275\n",
      "Train Epoch: 5 [6080/7119 (85%)] Loss: 0.490359\n",
      "Train Epoch: 5 [6144/7119 (86%)] Loss: 0.439876\n",
      "Train Epoch: 5 [6208/7119 (87%)] Loss: 0.284860\n",
      "Train Epoch: 5 [6272/7119 (88%)] Loss: 0.194964\n",
      "Train Epoch: 5 [6336/7119 (89%)] Loss: 0.523584\n",
      "Train Epoch: 5 [6400/7119 (90%)] Loss: 0.192498\n",
      "Train Epoch: 5 [6464/7119 (91%)] Loss: 0.242984\n",
      "Train Epoch: 5 [6528/7119 (92%)] Loss: 0.506313\n",
      "Train Epoch: 5 [6592/7119 (93%)] Loss: 0.321933\n",
      "Train Epoch: 5 [6656/7119 (93%)] Loss: 0.528887\n",
      "Train Epoch: 5 [6720/7119 (94%)] Loss: 0.170921\n",
      "Train Epoch: 5 [6784/7119 (95%)] Loss: 0.264195\n",
      "Train Epoch: 5 [6848/7119 (96%)] Loss: 0.428547\n",
      "Train Epoch: 5 [6912/7119 (97%)] Loss: 0.304563\n",
      "Train Epoch: 5 [6976/7119 (98%)] Loss: 0.455145\n",
      "Train Epoch: 5 [7040/7119 (99%)] Loss: 0.574533\n",
      "Train Epoch: 5 [7104/7119 (100%)] Loss: 0.357847\n",
      "    epoch          : 5\n",
      "    loss           : 0.3495047388284394\n",
      "    accuracy       : 0.848436329588015\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.31140683732926844\n",
      "    val_accuracy   : 0.87125\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch5.pth ...\n",
      "Train Epoch: 6 [0/7119 (0%)] Loss: 0.669868\n",
      "Train Epoch: 6 [64/7119 (1%)] Loss: 0.218084\n",
      "Train Epoch: 6 [128/7119 (2%)] Loss: 0.383559\n",
      "Train Epoch: 6 [192/7119 (3%)] Loss: 0.477015\n",
      "Train Epoch: 6 [256/7119 (4%)] Loss: 0.450913\n",
      "Train Epoch: 6 [320/7119 (4%)] Loss: 0.149854\n",
      "Train Epoch: 6 [384/7119 (5%)] Loss: 0.767848\n",
      "Train Epoch: 6 [448/7119 (6%)] Loss: 0.293123\n",
      "Train Epoch: 6 [512/7119 (7%)] Loss: 0.380910\n",
      "Train Epoch: 6 [576/7119 (8%)] Loss: 0.334258\n",
      "Train Epoch: 6 [640/7119 (9%)] Loss: 0.601902\n",
      "Train Epoch: 6 [704/7119 (10%)] Loss: 0.177820\n",
      "Train Epoch: 6 [768/7119 (11%)] Loss: 0.362710\n",
      "Train Epoch: 6 [832/7119 (12%)] Loss: 0.252063\n",
      "Train Epoch: 6 [896/7119 (13%)] Loss: 0.310723\n",
      "Train Epoch: 6 [960/7119 (13%)] Loss: 0.188084\n",
      "Train Epoch: 6 [1024/7119 (14%)] Loss: 0.289817\n",
      "Train Epoch: 6 [1088/7119 (15%)] Loss: 0.355922\n",
      "Train Epoch: 6 [1152/7119 (16%)] Loss: 0.291061\n",
      "Train Epoch: 6 [1216/7119 (17%)] Loss: 0.176799\n",
      "Train Epoch: 6 [1280/7119 (18%)] Loss: 0.172031\n",
      "Train Epoch: 6 [1344/7119 (19%)] Loss: 0.364824\n",
      "Train Epoch: 6 [1408/7119 (20%)] Loss: 0.492614\n",
      "Train Epoch: 6 [1472/7119 (21%)] Loss: 0.353260\n",
      "Train Epoch: 6 [1536/7119 (22%)] Loss: 0.123588\n",
      "Train Epoch: 6 [1600/7119 (22%)] Loss: 0.140534\n",
      "Train Epoch: 6 [1664/7119 (23%)] Loss: 0.326332\n",
      "Train Epoch: 6 [1728/7119 (24%)] Loss: 0.193359\n",
      "Train Epoch: 6 [1792/7119 (25%)] Loss: 0.263912\n",
      "Train Epoch: 6 [1856/7119 (26%)] Loss: 0.224580\n",
      "Train Epoch: 6 [1920/7119 (27%)] Loss: 0.229344\n",
      "Train Epoch: 6 [1984/7119 (28%)] Loss: 0.404021\n",
      "Train Epoch: 6 [2048/7119 (29%)] Loss: 0.196439\n",
      "Train Epoch: 6 [2112/7119 (30%)] Loss: 0.330860\n",
      "Train Epoch: 6 [2176/7119 (31%)] Loss: 0.230443\n",
      "Train Epoch: 6 [2240/7119 (31%)] Loss: 0.322320\n",
      "Train Epoch: 6 [2304/7119 (32%)] Loss: 0.267608\n",
      "Train Epoch: 6 [2368/7119 (33%)] Loss: 0.104323\n",
      "Train Epoch: 6 [2432/7119 (34%)] Loss: 0.146271\n",
      "Train Epoch: 6 [2496/7119 (35%)] Loss: 0.133933\n",
      "Train Epoch: 6 [2560/7119 (36%)] Loss: 0.351081\n",
      "Train Epoch: 6 [2624/7119 (37%)] Loss: 0.364237\n",
      "Train Epoch: 6 [2688/7119 (38%)] Loss: 0.312934\n",
      "Train Epoch: 6 [2752/7119 (39%)] Loss: 0.270952\n",
      "Train Epoch: 6 [2816/7119 (40%)] Loss: 0.686414\n",
      "Train Epoch: 6 [2880/7119 (40%)] Loss: 0.272780\n",
      "Train Epoch: 6 [2944/7119 (41%)] Loss: 0.256654\n",
      "Train Epoch: 6 [3008/7119 (42%)] Loss: 0.165445\n",
      "Train Epoch: 6 [3072/7119 (43%)] Loss: 0.166823\n",
      "Train Epoch: 6 [3136/7119 (44%)] Loss: 0.136132\n",
      "Train Epoch: 6 [3200/7119 (45%)] Loss: 0.364901\n",
      "Train Epoch: 6 [3264/7119 (46%)] Loss: 0.089303\n",
      "Train Epoch: 6 [3328/7119 (47%)] Loss: 0.335847\n",
      "Train Epoch: 6 [3392/7119 (48%)] Loss: 0.656181\n",
      "Train Epoch: 6 [3456/7119 (49%)] Loss: 1.004752\n",
      "Train Epoch: 6 [3520/7119 (49%)] Loss: 0.288791\n",
      "Train Epoch: 6 [3584/7119 (50%)] Loss: 0.176745\n",
      "Train Epoch: 6 [3648/7119 (51%)] Loss: 0.700587\n",
      "Train Epoch: 6 [3712/7119 (52%)] Loss: 0.296880\n",
      "Train Epoch: 6 [3776/7119 (53%)] Loss: 0.233460\n",
      "Train Epoch: 6 [3840/7119 (54%)] Loss: 0.204295\n",
      "Train Epoch: 6 [3904/7119 (55%)] Loss: 0.213616\n",
      "Train Epoch: 6 [3968/7119 (56%)] Loss: 0.723746\n",
      "Train Epoch: 6 [4032/7119 (57%)] Loss: 0.166682\n",
      "Train Epoch: 6 [4096/7119 (58%)] Loss: 0.336532\n",
      "Train Epoch: 6 [4160/7119 (58%)] Loss: 0.453678\n",
      "Train Epoch: 6 [4224/7119 (59%)] Loss: 0.421048\n",
      "Train Epoch: 6 [4288/7119 (60%)] Loss: 0.268485\n",
      "Train Epoch: 6 [4352/7119 (61%)] Loss: 0.362495\n",
      "Train Epoch: 6 [4416/7119 (62%)] Loss: 0.493950\n",
      "Train Epoch: 6 [4480/7119 (63%)] Loss: 0.093736\n",
      "Train Epoch: 6 [4544/7119 (64%)] Loss: 0.266906\n",
      "Train Epoch: 6 [4608/7119 (65%)] Loss: 0.337456\n",
      "Train Epoch: 6 [4672/7119 (66%)] Loss: 0.636251\n",
      "Train Epoch: 6 [4736/7119 (67%)] Loss: 0.481358\n",
      "Train Epoch: 6 [4800/7119 (67%)] Loss: 0.214558\n",
      "Train Epoch: 6 [4864/7119 (68%)] Loss: 0.213298\n",
      "Train Epoch: 6 [4928/7119 (69%)] Loss: 0.275133\n",
      "Train Epoch: 6 [4992/7119 (70%)] Loss: 0.468563\n",
      "Train Epoch: 6 [5056/7119 (71%)] Loss: 0.443117\n",
      "Train Epoch: 6 [5120/7119 (72%)] Loss: 0.304629\n",
      "Train Epoch: 6 [5184/7119 (73%)] Loss: 0.628189\n",
      "Train Epoch: 6 [5248/7119 (74%)] Loss: 0.614059\n",
      "Train Epoch: 6 [5312/7119 (75%)] Loss: 0.233392\n",
      "Train Epoch: 6 [5376/7119 (76%)] Loss: 0.179617\n",
      "Train Epoch: 6 [5440/7119 (76%)] Loss: 0.280164\n",
      "Train Epoch: 6 [5504/7119 (77%)] Loss: 0.187192\n",
      "Train Epoch: 6 [5568/7119 (78%)] Loss: 0.318627\n",
      "Train Epoch: 6 [5632/7119 (79%)] Loss: 0.559517\n",
      "Train Epoch: 6 [5696/7119 (80%)] Loss: 0.268272\n",
      "Train Epoch: 6 [5760/7119 (81%)] Loss: 0.257930\n",
      "Train Epoch: 6 [5824/7119 (82%)] Loss: 0.687229\n",
      "Train Epoch: 6 [5888/7119 (83%)] Loss: 0.518719\n",
      "Train Epoch: 6 [5952/7119 (84%)] Loss: 0.194049\n",
      "Train Epoch: 6 [6016/7119 (85%)] Loss: 0.497675\n",
      "Train Epoch: 6 [6080/7119 (85%)] Loss: 0.201045\n",
      "Train Epoch: 6 [6144/7119 (86%)] Loss: 0.268998\n",
      "Train Epoch: 6 [6208/7119 (87%)] Loss: 0.238703\n",
      "Train Epoch: 6 [6272/7119 (88%)] Loss: 0.378855\n",
      "Train Epoch: 6 [6336/7119 (89%)] Loss: 0.121652\n",
      "Train Epoch: 6 [6400/7119 (90%)] Loss: 0.544682\n",
      "Train Epoch: 6 [6464/7119 (91%)] Loss: 0.183406\n",
      "Train Epoch: 6 [6528/7119 (92%)] Loss: 0.399538\n",
      "Train Epoch: 6 [6592/7119 (93%)] Loss: 0.465735\n",
      "Train Epoch: 6 [6656/7119 (93%)] Loss: 0.114501\n",
      "Train Epoch: 6 [6720/7119 (94%)] Loss: 0.255208\n",
      "Train Epoch: 6 [6784/7119 (95%)] Loss: 0.346180\n",
      "Train Epoch: 6 [6848/7119 (96%)] Loss: 0.558758\n",
      "Train Epoch: 6 [6912/7119 (97%)] Loss: 0.229813\n",
      "Train Epoch: 6 [6976/7119 (98%)] Loss: 0.124285\n",
      "Train Epoch: 6 [7040/7119 (99%)] Loss: 0.339019\n",
      "Train Epoch: 6 [7104/7119 (100%)] Loss: 0.233541\n",
      "    epoch          : 6\n",
      "    loss           : 0.34209842879450725\n",
      "    accuracy       : 0.8565917602996255\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.27411805018782615\n",
      "    val_accuracy   : 0.8933333333333333\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch6.pth ...\n",
      "Train Epoch: 7 [0/7119 (0%)] Loss: 0.175009\n",
      "Train Epoch: 7 [64/7119 (1%)] Loss: 0.173517\n",
      "Train Epoch: 7 [128/7119 (2%)] Loss: 0.172478\n",
      "Train Epoch: 7 [192/7119 (3%)] Loss: 0.133576\n",
      "Train Epoch: 7 [256/7119 (4%)] Loss: 0.175352\n",
      "Train Epoch: 7 [320/7119 (4%)] Loss: 0.602606\n",
      "Train Epoch: 7 [384/7119 (5%)] Loss: 0.120935\n",
      "Train Epoch: 7 [448/7119 (6%)] Loss: 0.515050\n",
      "Train Epoch: 7 [512/7119 (7%)] Loss: 0.361747\n",
      "Train Epoch: 7 [576/7119 (8%)] Loss: 0.446954\n",
      "Train Epoch: 7 [640/7119 (9%)] Loss: 0.402162\n",
      "Train Epoch: 7 [704/7119 (10%)] Loss: 0.255357\n",
      "Train Epoch: 7 [768/7119 (11%)] Loss: 0.294686\n",
      "Train Epoch: 7 [832/7119 (12%)] Loss: 0.352917\n",
      "Train Epoch: 7 [896/7119 (13%)] Loss: 0.286365\n",
      "Train Epoch: 7 [960/7119 (13%)] Loss: 0.390118\n",
      "Train Epoch: 7 [1024/7119 (14%)] Loss: 0.348337\n",
      "Train Epoch: 7 [1088/7119 (15%)] Loss: 0.139717\n",
      "Train Epoch: 7 [1152/7119 (16%)] Loss: 0.655889\n",
      "Train Epoch: 7 [1216/7119 (17%)] Loss: 0.324620\n",
      "Train Epoch: 7 [1280/7119 (18%)] Loss: 0.404487\n",
      "Train Epoch: 7 [1344/7119 (19%)] Loss: 0.233042\n",
      "Train Epoch: 7 [1408/7119 (20%)] Loss: 0.521270\n",
      "Train Epoch: 7 [1472/7119 (21%)] Loss: 0.446087\n",
      "Train Epoch: 7 [1536/7119 (22%)] Loss: 0.214436\n",
      "Train Epoch: 7 [1600/7119 (22%)] Loss: 0.332804\n",
      "Train Epoch: 7 [1664/7119 (23%)] Loss: 0.291853\n",
      "Train Epoch: 7 [1728/7119 (24%)] Loss: 0.683714\n",
      "Train Epoch: 7 [1792/7119 (25%)] Loss: 0.152795\n",
      "Train Epoch: 7 [1856/7119 (26%)] Loss: 0.156008\n",
      "Train Epoch: 7 [1920/7119 (27%)] Loss: 0.300665\n",
      "Train Epoch: 7 [1984/7119 (28%)] Loss: 0.559574\n",
      "Train Epoch: 7 [2048/7119 (29%)] Loss: 0.344269\n",
      "Train Epoch: 7 [2112/7119 (30%)] Loss: 0.486100\n",
      "Train Epoch: 7 [2176/7119 (31%)] Loss: 0.218948\n",
      "Train Epoch: 7 [2240/7119 (31%)] Loss: 0.219017\n",
      "Train Epoch: 7 [2304/7119 (32%)] Loss: 0.621768\n",
      "Train Epoch: 7 [2368/7119 (33%)] Loss: 0.103805\n",
      "Train Epoch: 7 [2432/7119 (34%)] Loss: 0.284989\n",
      "Train Epoch: 7 [2496/7119 (35%)] Loss: 0.880634\n",
      "Train Epoch: 7 [2560/7119 (36%)] Loss: 0.172964\n",
      "Train Epoch: 7 [2624/7119 (37%)] Loss: 0.647297\n",
      "Train Epoch: 7 [2688/7119 (38%)] Loss: 0.223249\n",
      "Train Epoch: 7 [2752/7119 (39%)] Loss: 0.545576\n",
      "Train Epoch: 7 [2816/7119 (40%)] Loss: 0.480495\n",
      "Train Epoch: 7 [2880/7119 (40%)] Loss: 0.397821\n",
      "Train Epoch: 7 [2944/7119 (41%)] Loss: 0.546988\n",
      "Train Epoch: 7 [3008/7119 (42%)] Loss: 0.240357\n",
      "Train Epoch: 7 [3072/7119 (43%)] Loss: 0.201191\n",
      "Train Epoch: 7 [3136/7119 (44%)] Loss: 0.333208\n",
      "Train Epoch: 7 [3200/7119 (45%)] Loss: 0.208493\n",
      "Train Epoch: 7 [3264/7119 (46%)] Loss: 0.319671\n",
      "Train Epoch: 7 [3328/7119 (47%)] Loss: 0.225046\n",
      "Train Epoch: 7 [3392/7119 (48%)] Loss: 0.156072\n",
      "Train Epoch: 7 [3456/7119 (49%)] Loss: 0.372082\n",
      "Train Epoch: 7 [3520/7119 (49%)] Loss: 0.130676\n",
      "Train Epoch: 7 [3584/7119 (50%)] Loss: 0.261440\n",
      "Train Epoch: 7 [3648/7119 (51%)] Loss: 0.205747\n",
      "Train Epoch: 7 [3712/7119 (52%)] Loss: 0.479337\n",
      "Train Epoch: 7 [3776/7119 (53%)] Loss: 0.621631\n",
      "Train Epoch: 7 [3840/7119 (54%)] Loss: 0.303055\n",
      "Train Epoch: 7 [3904/7119 (55%)] Loss: 0.356234\n",
      "Train Epoch: 7 [3968/7119 (56%)] Loss: 0.449619\n",
      "Train Epoch: 7 [4032/7119 (57%)] Loss: 0.492403\n",
      "Train Epoch: 7 [4096/7119 (58%)] Loss: 0.150703\n",
      "Train Epoch: 7 [4160/7119 (58%)] Loss: 0.293293\n",
      "Train Epoch: 7 [4224/7119 (59%)] Loss: 0.317849\n",
      "Train Epoch: 7 [4288/7119 (60%)] Loss: 0.346013\n",
      "Train Epoch: 7 [4352/7119 (61%)] Loss: 0.448551\n",
      "Train Epoch: 7 [4416/7119 (62%)] Loss: 0.368336\n",
      "Train Epoch: 7 [4480/7119 (63%)] Loss: 0.236606\n",
      "Train Epoch: 7 [4544/7119 (64%)] Loss: 0.351293\n",
      "Train Epoch: 7 [4608/7119 (65%)] Loss: 0.337760\n",
      "Train Epoch: 7 [4672/7119 (66%)] Loss: 0.491102\n",
      "Train Epoch: 7 [4736/7119 (67%)] Loss: 0.599295\n",
      "Train Epoch: 7 [4800/7119 (67%)] Loss: 0.507272\n",
      "Train Epoch: 7 [4864/7119 (68%)] Loss: 0.184172\n",
      "Train Epoch: 7 [4928/7119 (69%)] Loss: 0.225157\n",
      "Train Epoch: 7 [4992/7119 (70%)] Loss: 0.309222\n",
      "Train Epoch: 7 [5056/7119 (71%)] Loss: 0.200905\n",
      "Train Epoch: 7 [5120/7119 (72%)] Loss: 0.185739\n",
      "Train Epoch: 7 [5184/7119 (73%)] Loss: 0.295196\n",
      "Train Epoch: 7 [5248/7119 (74%)] Loss: 0.577692\n",
      "Train Epoch: 7 [5312/7119 (75%)] Loss: 0.372542\n",
      "Train Epoch: 7 [5376/7119 (76%)] Loss: 0.537413\n",
      "Train Epoch: 7 [5440/7119 (76%)] Loss: 0.836483\n",
      "Train Epoch: 7 [5504/7119 (77%)] Loss: 0.314851\n",
      "Train Epoch: 7 [5568/7119 (78%)] Loss: 0.278442\n",
      "Train Epoch: 7 [5632/7119 (79%)] Loss: 0.187838\n",
      "Train Epoch: 7 [5696/7119 (80%)] Loss: 0.465484\n",
      "Train Epoch: 7 [5760/7119 (81%)] Loss: 0.432687\n",
      "Train Epoch: 7 [5824/7119 (82%)] Loss: 0.131169\n",
      "Train Epoch: 7 [5888/7119 (83%)] Loss: 0.367490\n",
      "Train Epoch: 7 [5952/7119 (84%)] Loss: 0.314782\n",
      "Train Epoch: 7 [6016/7119 (85%)] Loss: 0.360109\n",
      "Train Epoch: 7 [6080/7119 (85%)] Loss: 0.375355\n",
      "Train Epoch: 7 [6144/7119 (86%)] Loss: 0.110590\n",
      "Train Epoch: 7 [6208/7119 (87%)] Loss: 0.323384\n",
      "Train Epoch: 7 [6272/7119 (88%)] Loss: 0.237393\n",
      "Train Epoch: 7 [6336/7119 (89%)] Loss: 0.228455\n",
      "Train Epoch: 7 [6400/7119 (90%)] Loss: 0.500575\n",
      "Train Epoch: 7 [6464/7119 (91%)] Loss: 0.242637\n",
      "Train Epoch: 7 [6528/7119 (92%)] Loss: 0.357555\n",
      "Train Epoch: 7 [6592/7119 (93%)] Loss: 0.299475\n",
      "Train Epoch: 7 [6656/7119 (93%)] Loss: 0.149267\n",
      "Train Epoch: 7 [6720/7119 (94%)] Loss: 0.142577\n",
      "Train Epoch: 7 [6784/7119 (95%)] Loss: 0.159402\n",
      "Train Epoch: 7 [6848/7119 (96%)] Loss: 0.465993\n",
      "Train Epoch: 7 [6912/7119 (97%)] Loss: 0.466965\n",
      "Train Epoch: 7 [6976/7119 (98%)] Loss: 0.156783\n",
      "Train Epoch: 7 [7040/7119 (99%)] Loss: 0.406287\n",
      "Train Epoch: 7 [7104/7119 (100%)] Loss: 0.323106\n",
      "    epoch          : 7\n",
      "    loss           : 0.32847991173856717\n",
      "    accuracy       : 0.8560205992509363\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.2721149718761444\n",
      "    val_accuracy   : 0.8825\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch7.pth ...\n",
      "Train Epoch: 8 [0/7119 (0%)] Loss: 0.134079\n",
      "Train Epoch: 8 [64/7119 (1%)] Loss: 0.168924\n",
      "Train Epoch: 8 [128/7119 (2%)] Loss: 0.104985\n",
      "Train Epoch: 8 [192/7119 (3%)] Loss: 0.275542\n",
      "Train Epoch: 8 [256/7119 (4%)] Loss: 0.314065\n",
      "Train Epoch: 8 [320/7119 (4%)] Loss: 0.225369\n",
      "Train Epoch: 8 [384/7119 (5%)] Loss: 0.257317\n",
      "Train Epoch: 8 [448/7119 (6%)] Loss: 0.140098\n",
      "Train Epoch: 8 [512/7119 (7%)] Loss: 0.189274\n",
      "Train Epoch: 8 [576/7119 (8%)] Loss: 0.416026\n",
      "Train Epoch: 8 [640/7119 (9%)] Loss: 0.297722\n",
      "Train Epoch: 8 [704/7119 (10%)] Loss: 0.421380\n",
      "Train Epoch: 8 [768/7119 (11%)] Loss: 0.293643\n",
      "Train Epoch: 8 [832/7119 (12%)] Loss: 0.347886\n",
      "Train Epoch: 8 [896/7119 (13%)] Loss: 0.333497\n",
      "Train Epoch: 8 [960/7119 (13%)] Loss: 0.232006\n",
      "Train Epoch: 8 [1024/7119 (14%)] Loss: 0.256817\n",
      "Train Epoch: 8 [1088/7119 (15%)] Loss: 0.171394\n",
      "Train Epoch: 8 [1152/7119 (16%)] Loss: 0.347508\n",
      "Train Epoch: 8 [1216/7119 (17%)] Loss: 0.177901\n",
      "Train Epoch: 8 [1280/7119 (18%)] Loss: 0.357566\n",
      "Train Epoch: 8 [1344/7119 (19%)] Loss: 0.696983\n",
      "Train Epoch: 8 [1408/7119 (20%)] Loss: 0.366181\n",
      "Train Epoch: 8 [1472/7119 (21%)] Loss: 0.351385\n",
      "Train Epoch: 8 [1536/7119 (22%)] Loss: 0.512038\n",
      "Train Epoch: 8 [1600/7119 (22%)] Loss: 0.538110\n",
      "Train Epoch: 8 [1664/7119 (23%)] Loss: 0.440497\n",
      "Train Epoch: 8 [1728/7119 (24%)] Loss: 0.512778\n",
      "Train Epoch: 8 [1792/7119 (25%)] Loss: 0.103199\n",
      "Train Epoch: 8 [1856/7119 (26%)] Loss: 0.852928\n",
      "Train Epoch: 8 [1920/7119 (27%)] Loss: 0.167469\n",
      "Train Epoch: 8 [1984/7119 (28%)] Loss: 0.636543\n",
      "Train Epoch: 8 [2048/7119 (29%)] Loss: 0.410326\n",
      "Train Epoch: 8 [2112/7119 (30%)] Loss: 0.218195\n",
      "Train Epoch: 8 [2176/7119 (31%)] Loss: 0.565722\n",
      "Train Epoch: 8 [2240/7119 (31%)] Loss: 0.385400\n",
      "Train Epoch: 8 [2304/7119 (32%)] Loss: 0.099140\n",
      "Train Epoch: 8 [2368/7119 (33%)] Loss: 0.510104\n",
      "Train Epoch: 8 [2432/7119 (34%)] Loss: 0.368660\n",
      "Train Epoch: 8 [2496/7119 (35%)] Loss: 0.325109\n",
      "Train Epoch: 8 [2560/7119 (36%)] Loss: 0.392832\n",
      "Train Epoch: 8 [2624/7119 (37%)] Loss: 0.394581\n",
      "Train Epoch: 8 [2688/7119 (38%)] Loss: 0.550121\n",
      "Train Epoch: 8 [2752/7119 (39%)] Loss: 0.108273\n",
      "Train Epoch: 8 [2816/7119 (40%)] Loss: 0.441979\n",
      "Train Epoch: 8 [2880/7119 (40%)] Loss: 0.806929\n",
      "Train Epoch: 8 [2944/7119 (41%)] Loss: 0.199910\n",
      "Train Epoch: 8 [3008/7119 (42%)] Loss: 0.356968\n",
      "Train Epoch: 8 [3072/7119 (43%)] Loss: 0.564116\n",
      "Train Epoch: 8 [3136/7119 (44%)] Loss: 0.299029\n",
      "Train Epoch: 8 [3200/7119 (45%)] Loss: 0.231212\n",
      "Train Epoch: 8 [3264/7119 (46%)] Loss: 0.235683\n",
      "Train Epoch: 8 [3328/7119 (47%)] Loss: 0.216700\n",
      "Train Epoch: 8 [3392/7119 (48%)] Loss: 0.153449\n",
      "Train Epoch: 8 [3456/7119 (49%)] Loss: 0.253145\n",
      "Train Epoch: 8 [3520/7119 (49%)] Loss: 0.136793\n",
      "Train Epoch: 8 [3584/7119 (50%)] Loss: 0.154294\n",
      "Train Epoch: 8 [3648/7119 (51%)] Loss: 0.174655\n",
      "Train Epoch: 8 [3712/7119 (52%)] Loss: 0.303389\n",
      "Train Epoch: 8 [3776/7119 (53%)] Loss: 0.156180\n",
      "Train Epoch: 8 [3840/7119 (54%)] Loss: 0.290690\n",
      "Train Epoch: 8 [3904/7119 (55%)] Loss: 0.443306\n",
      "Train Epoch: 8 [3968/7119 (56%)] Loss: 0.298090\n",
      "Train Epoch: 8 [4032/7119 (57%)] Loss: 0.213474\n",
      "Train Epoch: 8 [4096/7119 (58%)] Loss: 0.301402\n",
      "Train Epoch: 8 [4160/7119 (58%)] Loss: 0.507878\n",
      "Train Epoch: 8 [4224/7119 (59%)] Loss: 0.786239\n",
      "Train Epoch: 8 [4288/7119 (60%)] Loss: 0.215430\n",
      "Train Epoch: 8 [4352/7119 (61%)] Loss: 0.157508\n",
      "Train Epoch: 8 [4416/7119 (62%)] Loss: 0.103493\n",
      "Train Epoch: 8 [4480/7119 (63%)] Loss: 0.407504\n",
      "Train Epoch: 8 [4544/7119 (64%)] Loss: 0.388536\n",
      "Train Epoch: 8 [4608/7119 (65%)] Loss: 0.228272\n",
      "Train Epoch: 8 [4672/7119 (66%)] Loss: 0.488489\n",
      "Train Epoch: 8 [4736/7119 (67%)] Loss: 0.199083\n",
      "Train Epoch: 8 [4800/7119 (67%)] Loss: 0.293311\n",
      "Train Epoch: 8 [4864/7119 (68%)] Loss: 0.182936\n",
      "Train Epoch: 8 [4928/7119 (69%)] Loss: 0.179362\n",
      "Train Epoch: 8 [4992/7119 (70%)] Loss: 0.280797\n",
      "Train Epoch: 8 [5056/7119 (71%)] Loss: 0.260558\n",
      "Train Epoch: 8 [5120/7119 (72%)] Loss: 0.192485\n",
      "Train Epoch: 8 [5184/7119 (73%)] Loss: 0.241778\n",
      "Train Epoch: 8 [5248/7119 (74%)] Loss: 0.492713\n",
      "Train Epoch: 8 [5312/7119 (75%)] Loss: 0.542314\n",
      "Train Epoch: 8 [5376/7119 (76%)] Loss: 0.239253\n",
      "Train Epoch: 8 [5440/7119 (76%)] Loss: 0.206327\n",
      "Train Epoch: 8 [5504/7119 (77%)] Loss: 0.488025\n",
      "Train Epoch: 8 [5568/7119 (78%)] Loss: 0.132743\n",
      "Train Epoch: 8 [5632/7119 (79%)] Loss: 0.681563\n",
      "Train Epoch: 8 [5696/7119 (80%)] Loss: 0.090076\n",
      "Train Epoch: 8 [5760/7119 (81%)] Loss: 0.385287\n",
      "Train Epoch: 8 [5824/7119 (82%)] Loss: 0.313711\n",
      "Train Epoch: 8 [5888/7119 (83%)] Loss: 0.269551\n",
      "Train Epoch: 8 [5952/7119 (84%)] Loss: 0.776105\n",
      "Train Epoch: 8 [6016/7119 (85%)] Loss: 0.126389\n",
      "Train Epoch: 8 [6080/7119 (85%)] Loss: 0.240397\n",
      "Train Epoch: 8 [6144/7119 (86%)] Loss: 0.116214\n",
      "Train Epoch: 8 [6208/7119 (87%)] Loss: 0.393549\n",
      "Train Epoch: 8 [6272/7119 (88%)] Loss: 0.296290\n",
      "Train Epoch: 8 [6336/7119 (89%)] Loss: 0.197810\n",
      "Train Epoch: 8 [6400/7119 (90%)] Loss: 0.422015\n",
      "Train Epoch: 8 [6464/7119 (91%)] Loss: 0.282048\n",
      "Train Epoch: 8 [6528/7119 (92%)] Loss: 0.120309\n",
      "Train Epoch: 8 [6592/7119 (93%)] Loss: 0.291025\n",
      "Train Epoch: 8 [6656/7119 (93%)] Loss: 0.272596\n",
      "Train Epoch: 8 [6720/7119 (94%)] Loss: 0.143246\n",
      "Train Epoch: 8 [6784/7119 (95%)] Loss: 0.518798\n",
      "Train Epoch: 8 [6848/7119 (96%)] Loss: 0.477062\n",
      "Train Epoch: 8 [6912/7119 (97%)] Loss: 0.219540\n",
      "Train Epoch: 8 [6976/7119 (98%)] Loss: 0.190737\n",
      "Train Epoch: 8 [7040/7119 (99%)] Loss: 0.321902\n",
      "Train Epoch: 8 [7104/7119 (100%)] Loss: 0.388074\n",
      "    epoch          : 8\n",
      "    loss           : 0.3281568546475989\n",
      "    accuracy       : 0.8606554307116105\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.2885547871142626\n",
      "    val_accuracy   : 0.8866666666666667\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch8.pth ...\n",
      "Train Epoch: 9 [0/7119 (0%)] Loss: 0.342959\n",
      "Train Epoch: 9 [64/7119 (1%)] Loss: 0.426803\n",
      "Train Epoch: 9 [128/7119 (2%)] Loss: 0.382914\n",
      "Train Epoch: 9 [192/7119 (3%)] Loss: 0.258165\n",
      "Train Epoch: 9 [256/7119 (4%)] Loss: 0.259914\n",
      "Train Epoch: 9 [320/7119 (4%)] Loss: 0.330985\n",
      "Train Epoch: 9 [384/7119 (5%)] Loss: 0.275115\n",
      "Train Epoch: 9 [448/7119 (6%)] Loss: 0.681633\n",
      "Train Epoch: 9 [512/7119 (7%)] Loss: 0.531455\n",
      "Train Epoch: 9 [576/7119 (8%)] Loss: 0.289553\n",
      "Train Epoch: 9 [640/7119 (9%)] Loss: 0.280618\n",
      "Train Epoch: 9 [704/7119 (10%)] Loss: 0.429150\n",
      "Train Epoch: 9 [768/7119 (11%)] Loss: 0.387919\n",
      "Train Epoch: 9 [832/7119 (12%)] Loss: 0.465504\n",
      "Train Epoch: 9 [896/7119 (13%)] Loss: 0.126182\n",
      "Train Epoch: 9 [960/7119 (13%)] Loss: 0.420065\n",
      "Train Epoch: 9 [1024/7119 (14%)] Loss: 0.493328\n",
      "Train Epoch: 9 [1088/7119 (15%)] Loss: 0.882485\n",
      "Train Epoch: 9 [1152/7119 (16%)] Loss: 0.168814\n",
      "Train Epoch: 9 [1216/7119 (17%)] Loss: 0.324329\n",
      "Train Epoch: 9 [1280/7119 (18%)] Loss: 0.223675\n",
      "Train Epoch: 9 [1344/7119 (19%)] Loss: 0.294899\n",
      "Train Epoch: 9 [1408/7119 (20%)] Loss: 0.331706\n",
      "Train Epoch: 9 [1472/7119 (21%)] Loss: 0.324805\n",
      "Train Epoch: 9 [1536/7119 (22%)] Loss: 0.481985\n",
      "Train Epoch: 9 [1600/7119 (22%)] Loss: 0.513327\n",
      "Train Epoch: 9 [1664/7119 (23%)] Loss: 0.359322\n",
      "Train Epoch: 9 [1728/7119 (24%)] Loss: 0.226135\n",
      "Train Epoch: 9 [1792/7119 (25%)] Loss: 0.469713\n",
      "Train Epoch: 9 [1856/7119 (26%)] Loss: 0.348337\n",
      "Train Epoch: 9 [1920/7119 (27%)] Loss: 0.514779\n",
      "Train Epoch: 9 [1984/7119 (28%)] Loss: 0.298514\n",
      "Train Epoch: 9 [2048/7119 (29%)] Loss: 0.541595\n",
      "Train Epoch: 9 [2112/7119 (30%)] Loss: 0.535688\n",
      "Train Epoch: 9 [2176/7119 (31%)] Loss: 0.308983\n",
      "Train Epoch: 9 [2240/7119 (31%)] Loss: 0.104356\n",
      "Train Epoch: 9 [2304/7119 (32%)] Loss: 0.210478\n",
      "Train Epoch: 9 [2368/7119 (33%)] Loss: 0.412805\n",
      "Train Epoch: 9 [2432/7119 (34%)] Loss: 0.311890\n",
      "Train Epoch: 9 [2496/7119 (35%)] Loss: 0.385481\n",
      "Train Epoch: 9 [2560/7119 (36%)] Loss: 0.340969\n",
      "Train Epoch: 9 [2624/7119 (37%)] Loss: 0.445426\n",
      "Train Epoch: 9 [2688/7119 (38%)] Loss: 0.416541\n",
      "Train Epoch: 9 [2752/7119 (39%)] Loss: 0.271008\n",
      "Train Epoch: 9 [2816/7119 (40%)] Loss: 0.356572\n",
      "Train Epoch: 9 [2880/7119 (40%)] Loss: 0.290051\n",
      "Train Epoch: 9 [2944/7119 (41%)] Loss: 0.178325\n",
      "Train Epoch: 9 [3008/7119 (42%)] Loss: 0.244083\n",
      "Train Epoch: 9 [3072/7119 (43%)] Loss: 0.449133\n",
      "Train Epoch: 9 [3136/7119 (44%)] Loss: 0.284903\n",
      "Train Epoch: 9 [3200/7119 (45%)] Loss: 0.277247\n",
      "Train Epoch: 9 [3264/7119 (46%)] Loss: 0.319838\n",
      "Train Epoch: 9 [3328/7119 (47%)] Loss: 0.352459\n",
      "Train Epoch: 9 [3392/7119 (48%)] Loss: 0.228122\n",
      "Train Epoch: 9 [3456/7119 (49%)] Loss: 0.422669\n",
      "Train Epoch: 9 [3520/7119 (49%)] Loss: 0.067955\n",
      "Train Epoch: 9 [3584/7119 (50%)] Loss: 0.152295\n",
      "Train Epoch: 9 [3648/7119 (51%)] Loss: 0.249618\n",
      "Train Epoch: 9 [3712/7119 (52%)] Loss: 0.244523\n",
      "Train Epoch: 9 [3776/7119 (53%)] Loss: 0.386865\n",
      "Train Epoch: 9 [3840/7119 (54%)] Loss: 0.149331\n",
      "Train Epoch: 9 [3904/7119 (55%)] Loss: 0.242489\n",
      "Train Epoch: 9 [3968/7119 (56%)] Loss: 0.054625\n",
      "Train Epoch: 9 [4032/7119 (57%)] Loss: 0.305452\n",
      "Train Epoch: 9 [4096/7119 (58%)] Loss: 0.290323\n",
      "Train Epoch: 9 [4160/7119 (58%)] Loss: 0.266856\n",
      "Train Epoch: 9 [4224/7119 (59%)] Loss: 0.311997\n",
      "Train Epoch: 9 [4288/7119 (60%)] Loss: 0.277813\n",
      "Train Epoch: 9 [4352/7119 (61%)] Loss: 0.071488\n",
      "Train Epoch: 9 [4416/7119 (62%)] Loss: 0.475403\n",
      "Train Epoch: 9 [4480/7119 (63%)] Loss: 0.251048\n",
      "Train Epoch: 9 [4544/7119 (64%)] Loss: 0.634767\n",
      "Train Epoch: 9 [4608/7119 (65%)] Loss: 0.330150\n",
      "Train Epoch: 9 [4672/7119 (66%)] Loss: 0.257820\n",
      "Train Epoch: 9 [4736/7119 (67%)] Loss: 0.296607\n",
      "Train Epoch: 9 [4800/7119 (67%)] Loss: 0.351644\n",
      "Train Epoch: 9 [4864/7119 (68%)] Loss: 0.493259\n",
      "Train Epoch: 9 [4928/7119 (69%)] Loss: 0.140660\n",
      "Train Epoch: 9 [4992/7119 (70%)] Loss: 0.197816\n",
      "Train Epoch: 9 [5056/7119 (71%)] Loss: 0.815299\n",
      "Train Epoch: 9 [5120/7119 (72%)] Loss: 0.307963\n",
      "Train Epoch: 9 [5184/7119 (73%)] Loss: 0.300659\n",
      "Train Epoch: 9 [5248/7119 (74%)] Loss: 0.612119\n",
      "Train Epoch: 9 [5312/7119 (75%)] Loss: 0.586827\n",
      "Train Epoch: 9 [5376/7119 (76%)] Loss: 0.109533\n",
      "Train Epoch: 9 [5440/7119 (76%)] Loss: 0.442173\n",
      "Train Epoch: 9 [5504/7119 (77%)] Loss: 0.334095\n",
      "Train Epoch: 9 [5568/7119 (78%)] Loss: 0.073793\n",
      "Train Epoch: 9 [5632/7119 (79%)] Loss: 0.295784\n",
      "Train Epoch: 9 [5696/7119 (80%)] Loss: 0.255632\n",
      "Train Epoch: 9 [5760/7119 (81%)] Loss: 0.191100\n",
      "Train Epoch: 9 [5824/7119 (82%)] Loss: 0.116442\n",
      "Train Epoch: 9 [5888/7119 (83%)] Loss: 0.193592\n",
      "Train Epoch: 9 [5952/7119 (84%)] Loss: 0.146437\n",
      "Train Epoch: 9 [6016/7119 (85%)] Loss: 0.132446\n",
      "Train Epoch: 9 [6080/7119 (85%)] Loss: 0.190266\n",
      "Train Epoch: 9 [6144/7119 (86%)] Loss: 0.154522\n",
      "Train Epoch: 9 [6208/7119 (87%)] Loss: 0.143564\n",
      "Train Epoch: 9 [6272/7119 (88%)] Loss: 0.149099\n",
      "Train Epoch: 9 [6336/7119 (89%)] Loss: 0.175016\n",
      "Train Epoch: 9 [6400/7119 (90%)] Loss: 0.433092\n",
      "Train Epoch: 9 [6464/7119 (91%)] Loss: 0.575896\n",
      "Train Epoch: 9 [6528/7119 (92%)] Loss: 0.568470\n",
      "Train Epoch: 9 [6592/7119 (93%)] Loss: 0.162949\n",
      "Train Epoch: 9 [6656/7119 (93%)] Loss: 0.479289\n",
      "Train Epoch: 9 [6720/7119 (94%)] Loss: 0.332108\n",
      "Train Epoch: 9 [6784/7119 (95%)] Loss: 0.339575\n",
      "Train Epoch: 9 [6848/7119 (96%)] Loss: 0.569710\n",
      "Train Epoch: 9 [6912/7119 (97%)] Loss: 0.630873\n",
      "Train Epoch: 9 [6976/7119 (98%)] Loss: 0.204679\n",
      "Train Epoch: 9 [7040/7119 (99%)] Loss: 0.222648\n",
      "Train Epoch: 9 [7104/7119 (100%)] Loss: 0.243635\n",
      "    epoch          : 9\n",
      "    loss           : 0.31871810069914613\n",
      "    accuracy       : 0.8624906367041199\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.26964097291231154\n",
      "    val_accuracy   : 0.8966666666666667\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch9.pth ...\n",
      "Train Epoch: 10 [0/7119 (0%)] Loss: 0.231077\n",
      "Train Epoch: 10 [64/7119 (1%)] Loss: 0.139574\n",
      "Train Epoch: 10 [128/7119 (2%)] Loss: 0.139301\n",
      "Train Epoch: 10 [192/7119 (3%)] Loss: 0.530803\n",
      "Train Epoch: 10 [256/7119 (4%)] Loss: 0.336357\n",
      "Train Epoch: 10 [320/7119 (4%)] Loss: 0.114270\n",
      "Train Epoch: 10 [384/7119 (5%)] Loss: 0.154720\n",
      "Train Epoch: 10 [448/7119 (6%)] Loss: 0.154754\n",
      "Train Epoch: 10 [512/7119 (7%)] Loss: 0.446637\n",
      "Train Epoch: 10 [576/7119 (8%)] Loss: 0.616677\n",
      "Train Epoch: 10 [640/7119 (9%)] Loss: 0.300886\n",
      "Train Epoch: 10 [704/7119 (10%)] Loss: 0.423311\n",
      "Train Epoch: 10 [768/7119 (11%)] Loss: 0.114986\n",
      "Train Epoch: 10 [832/7119 (12%)] Loss: 0.191590\n",
      "Train Epoch: 10 [896/7119 (13%)] Loss: 0.231835\n",
      "Train Epoch: 10 [960/7119 (13%)] Loss: 0.294676\n",
      "Train Epoch: 10 [1024/7119 (14%)] Loss: 0.391974\n",
      "Train Epoch: 10 [1088/7119 (15%)] Loss: 0.115896\n",
      "Train Epoch: 10 [1152/7119 (16%)] Loss: 0.282758\n",
      "Train Epoch: 10 [1216/7119 (17%)] Loss: 0.214157\n",
      "Train Epoch: 10 [1280/7119 (18%)] Loss: 0.366367\n",
      "Train Epoch: 10 [1344/7119 (19%)] Loss: 0.264842\n",
      "Train Epoch: 10 [1408/7119 (20%)] Loss: 0.211761\n",
      "Train Epoch: 10 [1472/7119 (21%)] Loss: 0.435115\n",
      "Train Epoch: 10 [1536/7119 (22%)] Loss: 0.602361\n",
      "Train Epoch: 10 [1600/7119 (22%)] Loss: 0.341852\n",
      "Train Epoch: 10 [1664/7119 (23%)] Loss: 0.172973\n",
      "Train Epoch: 10 [1728/7119 (24%)] Loss: 0.261053\n",
      "Train Epoch: 10 [1792/7119 (25%)] Loss: 0.264104\n",
      "Train Epoch: 10 [1856/7119 (26%)] Loss: 0.413044\n",
      "Train Epoch: 10 [1920/7119 (27%)] Loss: 0.337916\n",
      "Train Epoch: 10 [1984/7119 (28%)] Loss: 0.171835\n",
      "Train Epoch: 10 [2048/7119 (29%)] Loss: 0.469793\n",
      "Train Epoch: 10 [2112/7119 (30%)] Loss: 0.157056\n",
      "Train Epoch: 10 [2176/7119 (31%)] Loss: 0.358099\n",
      "Train Epoch: 10 [2240/7119 (31%)] Loss: 0.421458\n",
      "Train Epoch: 10 [2304/7119 (32%)] Loss: 0.768132\n",
      "Train Epoch: 10 [2368/7119 (33%)] Loss: 0.355165\n",
      "Train Epoch: 10 [2432/7119 (34%)] Loss: 0.425908\n",
      "Train Epoch: 10 [2496/7119 (35%)] Loss: 0.247270\n",
      "Train Epoch: 10 [2560/7119 (36%)] Loss: 0.342228\n",
      "Train Epoch: 10 [2624/7119 (37%)] Loss: 0.462644\n",
      "Train Epoch: 10 [2688/7119 (38%)] Loss: 0.502401\n",
      "Train Epoch: 10 [2752/7119 (39%)] Loss: 0.604047\n",
      "Train Epoch: 10 [2816/7119 (40%)] Loss: 0.372636\n",
      "Train Epoch: 10 [2880/7119 (40%)] Loss: 0.189342\n",
      "Train Epoch: 10 [2944/7119 (41%)] Loss: 0.306155\n",
      "Train Epoch: 10 [3008/7119 (42%)] Loss: 0.204094\n",
      "Train Epoch: 10 [3072/7119 (43%)] Loss: 0.252646\n",
      "Train Epoch: 10 [3136/7119 (44%)] Loss: 0.504622\n",
      "Train Epoch: 10 [3200/7119 (45%)] Loss: 0.179123\n",
      "Train Epoch: 10 [3264/7119 (46%)] Loss: 0.445256\n",
      "Train Epoch: 10 [3328/7119 (47%)] Loss: 0.310612\n",
      "Train Epoch: 10 [3392/7119 (48%)] Loss: 0.143028\n",
      "Train Epoch: 10 [3456/7119 (49%)] Loss: 0.064802\n",
      "Train Epoch: 10 [3520/7119 (49%)] Loss: 0.176228\n",
      "Train Epoch: 10 [3584/7119 (50%)] Loss: 0.176952\n",
      "Train Epoch: 10 [3648/7119 (51%)] Loss: 0.128051\n",
      "Train Epoch: 10 [3712/7119 (52%)] Loss: 0.284476\n",
      "Train Epoch: 10 [3776/7119 (53%)] Loss: 0.510634\n",
      "Train Epoch: 10 [3840/7119 (54%)] Loss: 0.295537\n",
      "Train Epoch: 10 [3904/7119 (55%)] Loss: 0.301113\n",
      "Train Epoch: 10 [3968/7119 (56%)] Loss: 0.537443\n",
      "Train Epoch: 10 [4032/7119 (57%)] Loss: 0.182295\n",
      "Train Epoch: 10 [4096/7119 (58%)] Loss: 0.434411\n",
      "Train Epoch: 10 [4160/7119 (58%)] Loss: 0.411101\n",
      "Train Epoch: 10 [4224/7119 (59%)] Loss: 0.454736\n",
      "Train Epoch: 10 [4288/7119 (60%)] Loss: 0.206613\n",
      "Train Epoch: 10 [4352/7119 (61%)] Loss: 0.157008\n",
      "Train Epoch: 10 [4416/7119 (62%)] Loss: 0.131353\n",
      "Train Epoch: 10 [4480/7119 (63%)] Loss: 0.242905\n",
      "Train Epoch: 10 [4544/7119 (64%)] Loss: 0.420208\n",
      "Train Epoch: 10 [4608/7119 (65%)] Loss: 0.360548\n",
      "Train Epoch: 10 [4672/7119 (66%)] Loss: 0.690038\n",
      "Train Epoch: 10 [4736/7119 (67%)] Loss: 0.116584\n",
      "Train Epoch: 10 [4800/7119 (67%)] Loss: 0.148811\n",
      "Train Epoch: 10 [4864/7119 (68%)] Loss: 0.302463\n",
      "Train Epoch: 10 [4928/7119 (69%)] Loss: 0.409598\n",
      "Train Epoch: 10 [4992/7119 (70%)] Loss: 0.233841\n",
      "Train Epoch: 10 [5056/7119 (71%)] Loss: 0.157270\n",
      "Train Epoch: 10 [5120/7119 (72%)] Loss: 0.329918\n",
      "Train Epoch: 10 [5184/7119 (73%)] Loss: 0.132336\n",
      "Train Epoch: 10 [5248/7119 (74%)] Loss: 0.165394\n",
      "Train Epoch: 10 [5312/7119 (75%)] Loss: 0.170137\n",
      "Train Epoch: 10 [5376/7119 (76%)] Loss: 0.549539\n",
      "Train Epoch: 10 [5440/7119 (76%)] Loss: 0.328008\n",
      "Train Epoch: 10 [5504/7119 (77%)] Loss: 0.426566\n",
      "Train Epoch: 10 [5568/7119 (78%)] Loss: 0.307182\n",
      "Train Epoch: 10 [5632/7119 (79%)] Loss: 0.483987\n",
      "Train Epoch: 10 [5696/7119 (80%)] Loss: 0.441694\n",
      "Train Epoch: 10 [5760/7119 (81%)] Loss: 0.098820\n",
      "Train Epoch: 10 [5824/7119 (82%)] Loss: 0.333301\n",
      "Train Epoch: 10 [5888/7119 (83%)] Loss: 0.263322\n",
      "Train Epoch: 10 [5952/7119 (84%)] Loss: 0.377299\n",
      "Train Epoch: 10 [6016/7119 (85%)] Loss: 0.139158\n",
      "Train Epoch: 10 [6080/7119 (85%)] Loss: 0.253118\n",
      "Train Epoch: 10 [6144/7119 (86%)] Loss: 0.548810\n",
      "Train Epoch: 10 [6208/7119 (87%)] Loss: 0.207401\n",
      "Train Epoch: 10 [6272/7119 (88%)] Loss: 0.185326\n",
      "Train Epoch: 10 [6336/7119 (89%)] Loss: 0.225851\n",
      "Train Epoch: 10 [6400/7119 (90%)] Loss: 0.412402\n",
      "Train Epoch: 10 [6464/7119 (91%)] Loss: 0.250075\n",
      "Train Epoch: 10 [6528/7119 (92%)] Loss: 0.449086\n",
      "Train Epoch: 10 [6592/7119 (93%)] Loss: 0.122284\n",
      "Train Epoch: 10 [6656/7119 (93%)] Loss: 0.395147\n",
      "Train Epoch: 10 [6720/7119 (94%)] Loss: 0.725277\n",
      "Train Epoch: 10 [6784/7119 (95%)] Loss: 0.519668\n",
      "Train Epoch: 10 [6848/7119 (96%)] Loss: 0.269770\n",
      "Train Epoch: 10 [6912/7119 (97%)] Loss: 0.393073\n",
      "Train Epoch: 10 [6976/7119 (98%)] Loss: 0.247670\n",
      "Train Epoch: 10 [7040/7119 (99%)] Loss: 0.378287\n",
      "Train Epoch: 10 [7104/7119 (100%)] Loss: 0.337311\n",
      "    epoch          : 10\n",
      "    loss           : 0.32671934776426703\n",
      "    accuracy       : 0.8612078651685393\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.27266320019960405\n",
      "    val_accuracy   : 0.89375\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch10.pth ...\n",
      "Train Epoch: 11 [0/7119 (0%)] Loss: 0.212148\n",
      "Train Epoch: 11 [64/7119 (1%)] Loss: 0.348402\n",
      "Train Epoch: 11 [128/7119 (2%)] Loss: 0.210393\n",
      "Train Epoch: 11 [192/7119 (3%)] Loss: 0.272871\n",
      "Train Epoch: 11 [256/7119 (4%)] Loss: 0.220632\n",
      "Train Epoch: 11 [320/7119 (4%)] Loss: 0.313931\n",
      "Train Epoch: 11 [384/7119 (5%)] Loss: 0.200821\n",
      "Train Epoch: 11 [448/7119 (6%)] Loss: 0.172903\n",
      "Train Epoch: 11 [512/7119 (7%)] Loss: 0.086576\n",
      "Train Epoch: 11 [576/7119 (8%)] Loss: 0.466220\n",
      "Train Epoch: 11 [640/7119 (9%)] Loss: 0.138093\n",
      "Train Epoch: 11 [704/7119 (10%)] Loss: 0.662122\n",
      "Train Epoch: 11 [768/7119 (11%)] Loss: 0.437656\n",
      "Train Epoch: 11 [832/7119 (12%)] Loss: 0.327406\n",
      "Train Epoch: 11 [896/7119 (13%)] Loss: 0.108571\n",
      "Train Epoch: 11 [960/7119 (13%)] Loss: 0.621219\n",
      "Train Epoch: 11 [1024/7119 (14%)] Loss: 0.433011\n",
      "Train Epoch: 11 [1088/7119 (15%)] Loss: 0.273115\n",
      "Train Epoch: 11 [1152/7119 (16%)] Loss: 0.344051\n",
      "Train Epoch: 11 [1216/7119 (17%)] Loss: 0.360519\n",
      "Train Epoch: 11 [1280/7119 (18%)] Loss: 0.316188\n",
      "Train Epoch: 11 [1344/7119 (19%)] Loss: 0.478868\n",
      "Train Epoch: 11 [1408/7119 (20%)] Loss: 0.241231\n",
      "Train Epoch: 11 [1472/7119 (21%)] Loss: 0.310889\n",
      "Train Epoch: 11 [1536/7119 (22%)] Loss: 0.408685\n",
      "Train Epoch: 11 [1600/7119 (22%)] Loss: 0.422894\n",
      "Train Epoch: 11 [1664/7119 (23%)] Loss: 0.642701\n",
      "Train Epoch: 11 [1728/7119 (24%)] Loss: 0.258555\n",
      "Train Epoch: 11 [1792/7119 (25%)] Loss: 0.186874\n",
      "Train Epoch: 11 [1856/7119 (26%)] Loss: 0.434282\n",
      "Train Epoch: 11 [1920/7119 (27%)] Loss: 0.159350\n",
      "Train Epoch: 11 [1984/7119 (28%)] Loss: 0.178040\n",
      "Train Epoch: 11 [2048/7119 (29%)] Loss: 0.381591\n",
      "Train Epoch: 11 [2112/7119 (30%)] Loss: 0.390600\n",
      "Train Epoch: 11 [2176/7119 (31%)] Loss: 0.486697\n",
      "Train Epoch: 11 [2240/7119 (31%)] Loss: 0.569032\n",
      "Train Epoch: 11 [2304/7119 (32%)] Loss: 0.491731\n",
      "Train Epoch: 11 [2368/7119 (33%)] Loss: 0.260494\n",
      "Train Epoch: 11 [2432/7119 (34%)] Loss: 0.957190\n",
      "Train Epoch: 11 [2496/7119 (35%)] Loss: 0.264090\n",
      "Train Epoch: 11 [2560/7119 (36%)] Loss: 0.400349\n",
      "Train Epoch: 11 [2624/7119 (37%)] Loss: 0.391180\n",
      "Train Epoch: 11 [2688/7119 (38%)] Loss: 0.114359\n",
      "Train Epoch: 11 [2752/7119 (39%)] Loss: 0.381499\n",
      "Train Epoch: 11 [2816/7119 (40%)] Loss: 0.375483\n",
      "Train Epoch: 11 [2880/7119 (40%)] Loss: 0.309571\n",
      "Train Epoch: 11 [2944/7119 (41%)] Loss: 0.190305\n",
      "Train Epoch: 11 [3008/7119 (42%)] Loss: 0.250196\n",
      "Train Epoch: 11 [3072/7119 (43%)] Loss: 0.267471\n",
      "Train Epoch: 11 [3136/7119 (44%)] Loss: 0.235148\n",
      "Train Epoch: 11 [3200/7119 (45%)] Loss: 0.223848\n",
      "Train Epoch: 11 [3264/7119 (46%)] Loss: 0.154858\n",
      "Train Epoch: 11 [3328/7119 (47%)] Loss: 0.178630\n",
      "Train Epoch: 11 [3392/7119 (48%)] Loss: 0.188430\n",
      "Train Epoch: 11 [3456/7119 (49%)] Loss: 0.455090\n",
      "Train Epoch: 11 [3520/7119 (49%)] Loss: 0.112104\n",
      "Train Epoch: 11 [3584/7119 (50%)] Loss: 0.258722\n",
      "Train Epoch: 11 [3648/7119 (51%)] Loss: 0.189696\n",
      "Train Epoch: 11 [3712/7119 (52%)] Loss: 0.280095\n",
      "Train Epoch: 11 [3776/7119 (53%)] Loss: 0.291071\n",
      "Train Epoch: 11 [3840/7119 (54%)] Loss: 0.265692\n",
      "Train Epoch: 11 [3904/7119 (55%)] Loss: 0.534369\n",
      "Train Epoch: 11 [3968/7119 (56%)] Loss: 0.237268\n",
      "Train Epoch: 11 [4032/7119 (57%)] Loss: 1.152447\n",
      "Train Epoch: 11 [4096/7119 (58%)] Loss: 0.489809\n",
      "Train Epoch: 11 [4160/7119 (58%)] Loss: 0.592694\n",
      "Train Epoch: 11 [4224/7119 (59%)] Loss: 0.211497\n",
      "Train Epoch: 11 [4288/7119 (60%)] Loss: 0.343682\n",
      "Train Epoch: 11 [4352/7119 (61%)] Loss: 0.392447\n",
      "Train Epoch: 11 [4416/7119 (62%)] Loss: 0.342248\n",
      "Train Epoch: 11 [4480/7119 (63%)] Loss: 0.279556\n",
      "Train Epoch: 11 [4544/7119 (64%)] Loss: 0.426751\n",
      "Train Epoch: 11 [4608/7119 (65%)] Loss: 0.167593\n",
      "Train Epoch: 11 [4672/7119 (66%)] Loss: 0.366221\n",
      "Train Epoch: 11 [4736/7119 (67%)] Loss: 0.156650\n",
      "Train Epoch: 11 [4800/7119 (67%)] Loss: 0.171303\n",
      "Train Epoch: 11 [4864/7119 (68%)] Loss: 0.508370\n",
      "Train Epoch: 11 [4928/7119 (69%)] Loss: 0.123472\n",
      "Train Epoch: 11 [4992/7119 (70%)] Loss: 0.248951\n",
      "Train Epoch: 11 [5056/7119 (71%)] Loss: 0.635646\n",
      "Train Epoch: 11 [5120/7119 (72%)] Loss: 0.193245\n",
      "Train Epoch: 11 [5184/7119 (73%)] Loss: 0.116494\n",
      "Train Epoch: 11 [5248/7119 (74%)] Loss: 0.167608\n",
      "Train Epoch: 11 [5312/7119 (75%)] Loss: 0.530126\n",
      "Train Epoch: 11 [5376/7119 (76%)] Loss: 0.256278\n",
      "Train Epoch: 11 [5440/7119 (76%)] Loss: 0.436200\n",
      "Train Epoch: 11 [5504/7119 (77%)] Loss: 0.380941\n",
      "Train Epoch: 11 [5568/7119 (78%)] Loss: 0.197630\n",
      "Train Epoch: 11 [5632/7119 (79%)] Loss: 0.344131\n",
      "Train Epoch: 11 [5696/7119 (80%)] Loss: 0.771508\n",
      "Train Epoch: 11 [5760/7119 (81%)] Loss: 0.429951\n",
      "Train Epoch: 11 [5824/7119 (82%)] Loss: 0.407553\n",
      "Train Epoch: 11 [5888/7119 (83%)] Loss: 0.518113\n",
      "Train Epoch: 11 [5952/7119 (84%)] Loss: 0.863265\n",
      "Train Epoch: 11 [6016/7119 (85%)] Loss: 0.230377\n",
      "Train Epoch: 11 [6080/7119 (85%)] Loss: 0.340752\n",
      "Train Epoch: 11 [6144/7119 (86%)] Loss: 0.241270\n",
      "Train Epoch: 11 [6208/7119 (87%)] Loss: 0.658713\n",
      "Train Epoch: 11 [6272/7119 (88%)] Loss: 0.503520\n",
      "Train Epoch: 11 [6336/7119 (89%)] Loss: 0.562810\n",
      "Train Epoch: 11 [6400/7119 (90%)] Loss: 0.691796\n",
      "Train Epoch: 11 [6464/7119 (91%)] Loss: 0.504634\n",
      "Train Epoch: 11 [6528/7119 (92%)] Loss: 0.423944\n",
      "Train Epoch: 11 [6592/7119 (93%)] Loss: 0.198363\n",
      "Train Epoch: 11 [6656/7119 (93%)] Loss: 0.247273\n",
      "Train Epoch: 11 [6720/7119 (94%)] Loss: 0.470676\n",
      "Train Epoch: 11 [6784/7119 (95%)] Loss: 0.301283\n",
      "Train Epoch: 11 [6848/7119 (96%)] Loss: 0.383882\n",
      "Train Epoch: 11 [6912/7119 (97%)] Loss: 0.459271\n",
      "Train Epoch: 11 [6976/7119 (98%)] Loss: 0.154076\n",
      "Train Epoch: 11 [7040/7119 (99%)] Loss: 0.576918\n",
      "Train Epoch: 11 [7104/7119 (100%)] Loss: 0.573049\n",
      "    epoch          : 11\n",
      "    loss           : 0.32129748224207527\n",
      "    accuracy       : 0.8652715355805244\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.3007593710720539\n",
      "    val_accuracy   : 0.8691666666666668\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch11.pth ...\n",
      "Train Epoch: 12 [0/7119 (0%)] Loss: 0.193067\n",
      "Train Epoch: 12 [64/7119 (1%)] Loss: 0.225228\n",
      "Train Epoch: 12 [128/7119 (2%)] Loss: 0.347760\n",
      "Train Epoch: 12 [192/7119 (3%)] Loss: 0.224195\n",
      "Train Epoch: 12 [256/7119 (4%)] Loss: 0.125204\n",
      "Train Epoch: 12 [320/7119 (4%)] Loss: 0.471119\n",
      "Train Epoch: 12 [384/7119 (5%)] Loss: 0.469702\n",
      "Train Epoch: 12 [448/7119 (6%)] Loss: 0.254828\n",
      "Train Epoch: 12 [512/7119 (7%)] Loss: 0.340845\n",
      "Train Epoch: 12 [576/7119 (8%)] Loss: 0.198901\n",
      "Train Epoch: 12 [640/7119 (9%)] Loss: 0.277902\n",
      "Train Epoch: 12 [704/7119 (10%)] Loss: 0.529571\n",
      "Train Epoch: 12 [768/7119 (11%)] Loss: 0.131857\n",
      "Train Epoch: 12 [832/7119 (12%)] Loss: 0.360182\n",
      "Train Epoch: 12 [896/7119 (13%)] Loss: 0.248244\n",
      "Train Epoch: 12 [960/7119 (13%)] Loss: 0.493690\n",
      "Train Epoch: 12 [1024/7119 (14%)] Loss: 0.194532\n",
      "Train Epoch: 12 [1088/7119 (15%)] Loss: 0.208096\n",
      "Train Epoch: 12 [1152/7119 (16%)] Loss: 0.454434\n",
      "Train Epoch: 12 [1216/7119 (17%)] Loss: 0.248474\n",
      "Train Epoch: 12 [1280/7119 (18%)] Loss: 0.238898\n",
      "Train Epoch: 12 [1344/7119 (19%)] Loss: 0.266740\n",
      "Train Epoch: 12 [1408/7119 (20%)] Loss: 0.207076\n",
      "Train Epoch: 12 [1472/7119 (21%)] Loss: 0.229791\n",
      "Train Epoch: 12 [1536/7119 (22%)] Loss: 0.131721\n",
      "Train Epoch: 12 [1600/7119 (22%)] Loss: 0.206903\n",
      "Train Epoch: 12 [1664/7119 (23%)] Loss: 0.490158\n",
      "Train Epoch: 12 [1728/7119 (24%)] Loss: 0.287061\n",
      "Train Epoch: 12 [1792/7119 (25%)] Loss: 0.424896\n",
      "Train Epoch: 12 [1856/7119 (26%)] Loss: 0.103538\n",
      "Train Epoch: 12 [1920/7119 (27%)] Loss: 0.412750\n",
      "Train Epoch: 12 [1984/7119 (28%)] Loss: 0.159929\n",
      "Train Epoch: 12 [2048/7119 (29%)] Loss: 0.360655\n",
      "Train Epoch: 12 [2112/7119 (30%)] Loss: 0.449416\n",
      "Train Epoch: 12 [2176/7119 (31%)] Loss: 0.149427\n",
      "Train Epoch: 12 [2240/7119 (31%)] Loss: 0.309873\n",
      "Train Epoch: 12 [2304/7119 (32%)] Loss: 0.491506\n",
      "Train Epoch: 12 [2368/7119 (33%)] Loss: 0.348085\n",
      "Train Epoch: 12 [2432/7119 (34%)] Loss: 0.165714\n",
      "Train Epoch: 12 [2496/7119 (35%)] Loss: 0.440797\n",
      "Train Epoch: 12 [2560/7119 (36%)] Loss: 0.140718\n",
      "Train Epoch: 12 [2624/7119 (37%)] Loss: 0.557988\n",
      "Train Epoch: 12 [2688/7119 (38%)] Loss: 0.209961\n",
      "Train Epoch: 12 [2752/7119 (39%)] Loss: 0.312640\n",
      "Train Epoch: 12 [2816/7119 (40%)] Loss: 0.056775\n",
      "Train Epoch: 12 [2880/7119 (40%)] Loss: 0.731845\n",
      "Train Epoch: 12 [2944/7119 (41%)] Loss: 0.417502\n",
      "Train Epoch: 12 [3008/7119 (42%)] Loss: 0.281536\n",
      "Train Epoch: 12 [3072/7119 (43%)] Loss: 0.264498\n",
      "Train Epoch: 12 [3136/7119 (44%)] Loss: 0.453774\n",
      "Train Epoch: 12 [3200/7119 (45%)] Loss: 0.370206\n",
      "Train Epoch: 12 [3264/7119 (46%)] Loss: 0.286076\n",
      "Train Epoch: 12 [3328/7119 (47%)] Loss: 0.258226\n",
      "Train Epoch: 12 [3392/7119 (48%)] Loss: 0.213802\n",
      "Train Epoch: 12 [3456/7119 (49%)] Loss: 0.231595\n",
      "Train Epoch: 12 [3520/7119 (49%)] Loss: 0.272768\n",
      "Train Epoch: 12 [3584/7119 (50%)] Loss: 0.272228\n",
      "Train Epoch: 12 [3648/7119 (51%)] Loss: 0.102407\n",
      "Train Epoch: 12 [3712/7119 (52%)] Loss: 0.090020\n",
      "Train Epoch: 12 [3776/7119 (53%)] Loss: 0.660671\n",
      "Train Epoch: 12 [3840/7119 (54%)] Loss: 0.241614\n",
      "Train Epoch: 12 [3904/7119 (55%)] Loss: 0.447009\n",
      "Train Epoch: 12 [3968/7119 (56%)] Loss: 0.600285\n",
      "Train Epoch: 12 [4032/7119 (57%)] Loss: 0.262353\n",
      "Train Epoch: 12 [4096/7119 (58%)] Loss: 0.653568\n",
      "Train Epoch: 12 [4160/7119 (58%)] Loss: 0.232052\n",
      "Train Epoch: 12 [4224/7119 (59%)] Loss: 0.278545\n",
      "Train Epoch: 12 [4288/7119 (60%)] Loss: 0.616138\n",
      "Train Epoch: 12 [4352/7119 (61%)] Loss: 0.264382\n",
      "Train Epoch: 12 [4416/7119 (62%)] Loss: 0.239911\n",
      "Train Epoch: 12 [4480/7119 (63%)] Loss: 0.354712\n",
      "Train Epoch: 12 [4544/7119 (64%)] Loss: 0.514276\n",
      "Train Epoch: 12 [4608/7119 (65%)] Loss: 0.089979\n",
      "Train Epoch: 12 [4672/7119 (66%)] Loss: 0.057621\n",
      "Train Epoch: 12 [4736/7119 (67%)] Loss: 0.252445\n",
      "Train Epoch: 12 [4800/7119 (67%)] Loss: 0.117581\n",
      "Train Epoch: 12 [4864/7119 (68%)] Loss: 0.415133\n",
      "Train Epoch: 12 [4928/7119 (69%)] Loss: 0.159509\n",
      "Train Epoch: 12 [4992/7119 (70%)] Loss: 0.153457\n",
      "Train Epoch: 12 [5056/7119 (71%)] Loss: 0.458966\n",
      "Train Epoch: 12 [5120/7119 (72%)] Loss: 0.173222\n",
      "Train Epoch: 12 [5184/7119 (73%)] Loss: 0.370774\n",
      "Train Epoch: 12 [5248/7119 (74%)] Loss: 0.392981\n",
      "Train Epoch: 12 [5312/7119 (75%)] Loss: 0.227537\n",
      "Train Epoch: 12 [5376/7119 (76%)] Loss: 0.135192\n",
      "Train Epoch: 12 [5440/7119 (76%)] Loss: 0.419225\n",
      "Train Epoch: 12 [5504/7119 (77%)] Loss: 0.163807\n",
      "Train Epoch: 12 [5568/7119 (78%)] Loss: 0.333273\n",
      "Train Epoch: 12 [5632/7119 (79%)] Loss: 0.281827\n",
      "Train Epoch: 12 [5696/7119 (80%)] Loss: 0.394531\n",
      "Train Epoch: 12 [5760/7119 (81%)] Loss: 0.323797\n",
      "Train Epoch: 12 [5824/7119 (82%)] Loss: 0.326669\n",
      "Train Epoch: 12 [5888/7119 (83%)] Loss: 0.430869\n",
      "Train Epoch: 12 [5952/7119 (84%)] Loss: 0.267189\n",
      "Train Epoch: 12 [6016/7119 (85%)] Loss: 0.543886\n",
      "Train Epoch: 12 [6080/7119 (85%)] Loss: 0.238801\n",
      "Train Epoch: 12 [6144/7119 (86%)] Loss: 0.642499\n",
      "Train Epoch: 12 [6208/7119 (87%)] Loss: 0.152538\n",
      "Train Epoch: 12 [6272/7119 (88%)] Loss: 0.229969\n",
      "Train Epoch: 12 [6336/7119 (89%)] Loss: 0.473269\n",
      "Train Epoch: 12 [6400/7119 (90%)] Loss: 0.415573\n",
      "Train Epoch: 12 [6464/7119 (91%)] Loss: 0.074816\n",
      "Train Epoch: 12 [6528/7119 (92%)] Loss: 0.220158\n",
      "Train Epoch: 12 [6592/7119 (93%)] Loss: 0.199700\n",
      "Train Epoch: 12 [6656/7119 (93%)] Loss: 0.165664\n",
      "Train Epoch: 12 [6720/7119 (94%)] Loss: 0.572180\n",
      "Train Epoch: 12 [6784/7119 (95%)] Loss: 0.601001\n",
      "Train Epoch: 12 [6848/7119 (96%)] Loss: 0.332433\n",
      "Train Epoch: 12 [6912/7119 (97%)] Loss: 0.707836\n",
      "Train Epoch: 12 [6976/7119 (98%)] Loss: 0.159943\n",
      "Train Epoch: 12 [7040/7119 (99%)] Loss: 0.236698\n",
      "Train Epoch: 12 [7104/7119 (100%)] Loss: 0.096585\n",
      "    epoch          : 12\n",
      "    loss           : 0.31760975175191847\n",
      "    accuracy       : 0.8662921348314607\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.26523695446550843\n",
      "    val_accuracy   : 0.895\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch12.pth ...\n",
      "Train Epoch: 13 [0/7119 (0%)] Loss: 0.448029\n",
      "Train Epoch: 13 [64/7119 (1%)] Loss: 0.386943\n",
      "Train Epoch: 13 [128/7119 (2%)] Loss: 0.200521\n",
      "Train Epoch: 13 [192/7119 (3%)] Loss: 0.184450\n",
      "Train Epoch: 13 [256/7119 (4%)] Loss: 0.278017\n",
      "Train Epoch: 13 [320/7119 (4%)] Loss: 0.524043\n",
      "Train Epoch: 13 [384/7119 (5%)] Loss: 0.307421\n",
      "Train Epoch: 13 [448/7119 (6%)] Loss: 0.235244\n",
      "Train Epoch: 13 [512/7119 (7%)] Loss: 0.330199\n",
      "Train Epoch: 13 [576/7119 (8%)] Loss: 0.150411\n",
      "Train Epoch: 13 [640/7119 (9%)] Loss: 0.285760\n",
      "Train Epoch: 13 [704/7119 (10%)] Loss: 0.257735\n",
      "Train Epoch: 13 [768/7119 (11%)] Loss: 0.126088\n",
      "Train Epoch: 13 [832/7119 (12%)] Loss: 0.428733\n",
      "Train Epoch: 13 [896/7119 (13%)] Loss: 0.527767\n",
      "Train Epoch: 13 [960/7119 (13%)] Loss: 0.403762\n",
      "Train Epoch: 13 [1024/7119 (14%)] Loss: 0.534614\n",
      "Train Epoch: 13 [1088/7119 (15%)] Loss: 0.326934\n",
      "Train Epoch: 13 [1152/7119 (16%)] Loss: 0.173559\n",
      "Train Epoch: 13 [1216/7119 (17%)] Loss: 0.413871\n",
      "Train Epoch: 13 [1280/7119 (18%)] Loss: 0.149017\n",
      "Train Epoch: 13 [1344/7119 (19%)] Loss: 1.038866\n",
      "Train Epoch: 13 [1408/7119 (20%)] Loss: 0.102505\n",
      "Train Epoch: 13 [1472/7119 (21%)] Loss: 0.276061\n",
      "Train Epoch: 13 [1536/7119 (22%)] Loss: 0.604868\n",
      "Train Epoch: 13 [1600/7119 (22%)] Loss: 0.128284\n",
      "Train Epoch: 13 [1664/7119 (23%)] Loss: 0.716989\n",
      "Train Epoch: 13 [1728/7119 (24%)] Loss: 0.309029\n",
      "Train Epoch: 13 [1792/7119 (25%)] Loss: 0.155998\n",
      "Train Epoch: 13 [1856/7119 (26%)] Loss: 0.113782\n",
      "Train Epoch: 13 [1920/7119 (27%)] Loss: 0.204796\n",
      "Train Epoch: 13 [1984/7119 (28%)] Loss: 0.243938\n",
      "Train Epoch: 13 [2048/7119 (29%)] Loss: 0.414545\n",
      "Train Epoch: 13 [2112/7119 (30%)] Loss: 0.076900\n",
      "Train Epoch: 13 [2176/7119 (31%)] Loss: 0.492380\n",
      "Train Epoch: 13 [2240/7119 (31%)] Loss: 0.228946\n",
      "Train Epoch: 13 [2304/7119 (32%)] Loss: 0.436904\n",
      "Train Epoch: 13 [2368/7119 (33%)] Loss: 0.124320\n",
      "Train Epoch: 13 [2432/7119 (34%)] Loss: 0.226895\n",
      "Train Epoch: 13 [2496/7119 (35%)] Loss: 0.190629\n",
      "Train Epoch: 13 [2560/7119 (36%)] Loss: 0.326096\n",
      "Train Epoch: 13 [2624/7119 (37%)] Loss: 0.363478\n",
      "Train Epoch: 13 [2688/7119 (38%)] Loss: 0.139936\n",
      "Train Epoch: 13 [2752/7119 (39%)] Loss: 0.644510\n",
      "Train Epoch: 13 [2816/7119 (40%)] Loss: 0.127083\n",
      "Train Epoch: 13 [2880/7119 (40%)] Loss: 0.279110\n",
      "Train Epoch: 13 [2944/7119 (41%)] Loss: 0.296433\n",
      "Train Epoch: 13 [3008/7119 (42%)] Loss: 0.150549\n",
      "Train Epoch: 13 [3072/7119 (43%)] Loss: 0.469948\n",
      "Train Epoch: 13 [3136/7119 (44%)] Loss: 0.212323\n",
      "Train Epoch: 13 [3200/7119 (45%)] Loss: 0.452169\n",
      "Train Epoch: 13 [3264/7119 (46%)] Loss: 0.138496\n",
      "Train Epoch: 13 [3328/7119 (47%)] Loss: 0.403398\n",
      "Train Epoch: 13 [3392/7119 (48%)] Loss: 0.433277\n",
      "Train Epoch: 13 [3456/7119 (49%)] Loss: 0.229474\n",
      "Train Epoch: 13 [3520/7119 (49%)] Loss: 0.165616\n",
      "Train Epoch: 13 [3584/7119 (50%)] Loss: 0.500546\n",
      "Train Epoch: 13 [3648/7119 (51%)] Loss: 0.188649\n",
      "Train Epoch: 13 [3712/7119 (52%)] Loss: 0.224388\n",
      "Train Epoch: 13 [3776/7119 (53%)] Loss: 0.240460\n",
      "Train Epoch: 13 [3840/7119 (54%)] Loss: 0.082130\n",
      "Train Epoch: 13 [3904/7119 (55%)] Loss: 0.183634\n",
      "Train Epoch: 13 [3968/7119 (56%)] Loss: 0.384362\n",
      "Train Epoch: 13 [4032/7119 (57%)] Loss: 0.187659\n",
      "Train Epoch: 13 [4096/7119 (58%)] Loss: 0.152275\n",
      "Train Epoch: 13 [4160/7119 (58%)] Loss: 0.404348\n",
      "Train Epoch: 13 [4224/7119 (59%)] Loss: 0.305569\n",
      "Train Epoch: 13 [4288/7119 (60%)] Loss: 0.210006\n",
      "Train Epoch: 13 [4352/7119 (61%)] Loss: 0.221020\n",
      "Train Epoch: 13 [4416/7119 (62%)] Loss: 0.208562\n",
      "Train Epoch: 13 [4480/7119 (63%)] Loss: 0.174985\n",
      "Train Epoch: 13 [4544/7119 (64%)] Loss: 0.329867\n",
      "Train Epoch: 13 [4608/7119 (65%)] Loss: 0.454103\n",
      "Train Epoch: 13 [4672/7119 (66%)] Loss: 0.290067\n",
      "Train Epoch: 13 [4736/7119 (67%)] Loss: 0.222915\n",
      "Train Epoch: 13 [4800/7119 (67%)] Loss: 0.587039\n",
      "Train Epoch: 13 [4864/7119 (68%)] Loss: 0.542577\n",
      "Train Epoch: 13 [4928/7119 (69%)] Loss: 0.225109\n",
      "Train Epoch: 13 [4992/7119 (70%)] Loss: 0.501015\n",
      "Train Epoch: 13 [5056/7119 (71%)] Loss: 0.195656\n",
      "Train Epoch: 13 [5120/7119 (72%)] Loss: 0.223845\n",
      "Train Epoch: 13 [5184/7119 (73%)] Loss: 0.415903\n",
      "Train Epoch: 13 [5248/7119 (74%)] Loss: 0.047315\n",
      "Train Epoch: 13 [5312/7119 (75%)] Loss: 0.270861\n",
      "Train Epoch: 13 [5376/7119 (76%)] Loss: 0.274017\n",
      "Train Epoch: 13 [5440/7119 (76%)] Loss: 0.243812\n",
      "Train Epoch: 13 [5504/7119 (77%)] Loss: 0.384954\n",
      "Train Epoch: 13 [5568/7119 (78%)] Loss: 0.432537\n",
      "Train Epoch: 13 [5632/7119 (79%)] Loss: 0.235635\n",
      "Train Epoch: 13 [5696/7119 (80%)] Loss: 0.193089\n",
      "Train Epoch: 13 [5760/7119 (81%)] Loss: 0.360457\n",
      "Train Epoch: 13 [5824/7119 (82%)] Loss: 0.351704\n",
      "Train Epoch: 13 [5888/7119 (83%)] Loss: 0.292902\n",
      "Train Epoch: 13 [5952/7119 (84%)] Loss: 0.381953\n",
      "Train Epoch: 13 [6016/7119 (85%)] Loss: 0.613595\n",
      "Train Epoch: 13 [6080/7119 (85%)] Loss: 0.113704\n",
      "Train Epoch: 13 [6144/7119 (86%)] Loss: 0.343579\n",
      "Train Epoch: 13 [6208/7119 (87%)] Loss: 0.534553\n",
      "Train Epoch: 13 [6272/7119 (88%)] Loss: 0.640596\n",
      "Train Epoch: 13 [6336/7119 (89%)] Loss: 0.197277\n",
      "Train Epoch: 13 [6400/7119 (90%)] Loss: 0.341463\n",
      "Train Epoch: 13 [6464/7119 (91%)] Loss: 0.518701\n",
      "Train Epoch: 13 [6528/7119 (92%)] Loss: 0.306209\n",
      "Train Epoch: 13 [6592/7119 (93%)] Loss: 0.178079\n",
      "Train Epoch: 13 [6656/7119 (93%)] Loss: 0.457449\n",
      "Train Epoch: 13 [6720/7119 (94%)] Loss: 0.295999\n",
      "Train Epoch: 13 [6784/7119 (95%)] Loss: 0.255339\n",
      "Train Epoch: 13 [6848/7119 (96%)] Loss: 0.571710\n",
      "Train Epoch: 13 [6912/7119 (97%)] Loss: 0.191050\n",
      "Train Epoch: 13 [6976/7119 (98%)] Loss: 0.247203\n",
      "Train Epoch: 13 [7040/7119 (99%)] Loss: 0.582782\n",
      "Train Epoch: 13 [7104/7119 (100%)] Loss: 0.402921\n",
      "    epoch          : 13\n",
      "    loss           : 0.32967114272747144\n",
      "    accuracy       : 0.8634456928838952\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.2653904831036925\n",
      "    val_accuracy   : 0.8925\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch13.pth ...\n",
      "Train Epoch: 14 [0/7119 (0%)] Loss: 0.366362\n",
      "Train Epoch: 14 [64/7119 (1%)] Loss: 0.731045\n",
      "Train Epoch: 14 [128/7119 (2%)] Loss: 0.638129\n",
      "Train Epoch: 14 [192/7119 (3%)] Loss: 0.200527\n",
      "Train Epoch: 14 [256/7119 (4%)] Loss: 0.159184\n",
      "Train Epoch: 14 [320/7119 (4%)] Loss: 0.394652\n",
      "Train Epoch: 14 [384/7119 (5%)] Loss: 0.353544\n",
      "Train Epoch: 14 [448/7119 (6%)] Loss: 0.141094\n",
      "Train Epoch: 14 [512/7119 (7%)] Loss: 0.252275\n",
      "Train Epoch: 14 [576/7119 (8%)] Loss: 0.301694\n",
      "Train Epoch: 14 [640/7119 (9%)] Loss: 0.561010\n",
      "Train Epoch: 14 [704/7119 (10%)] Loss: 0.417983\n",
      "Train Epoch: 14 [768/7119 (11%)] Loss: 0.150207\n",
      "Train Epoch: 14 [832/7119 (12%)] Loss: 0.304720\n",
      "Train Epoch: 14 [896/7119 (13%)] Loss: 0.190729\n",
      "Train Epoch: 14 [960/7119 (13%)] Loss: 0.212420\n",
      "Train Epoch: 14 [1024/7119 (14%)] Loss: 0.407186\n",
      "Train Epoch: 14 [1088/7119 (15%)] Loss: 0.133965\n",
      "Train Epoch: 14 [1152/7119 (16%)] Loss: 0.164780\n",
      "Train Epoch: 14 [1216/7119 (17%)] Loss: 0.229589\n",
      "Train Epoch: 14 [1280/7119 (18%)] Loss: 0.253618\n",
      "Train Epoch: 14 [1344/7119 (19%)] Loss: 0.200789\n",
      "Train Epoch: 14 [1408/7119 (20%)] Loss: 0.275069\n",
      "Train Epoch: 14 [1472/7119 (21%)] Loss: 0.354761\n",
      "Train Epoch: 14 [1536/7119 (22%)] Loss: 0.306313\n",
      "Train Epoch: 14 [1600/7119 (22%)] Loss: 0.489343\n",
      "Train Epoch: 14 [1664/7119 (23%)] Loss: 0.293922\n",
      "Train Epoch: 14 [1728/7119 (24%)] Loss: 0.235954\n",
      "Train Epoch: 14 [1792/7119 (25%)] Loss: 0.587336\n",
      "Train Epoch: 14 [1856/7119 (26%)] Loss: 0.229742\n",
      "Train Epoch: 14 [1920/7119 (27%)] Loss: 0.476508\n",
      "Train Epoch: 14 [1984/7119 (28%)] Loss: 0.401188\n",
      "Train Epoch: 14 [2048/7119 (29%)] Loss: 0.345041\n",
      "Train Epoch: 14 [2112/7119 (30%)] Loss: 0.427145\n",
      "Train Epoch: 14 [2176/7119 (31%)] Loss: 0.194479\n",
      "Train Epoch: 14 [2240/7119 (31%)] Loss: 0.371554\n",
      "Train Epoch: 14 [2304/7119 (32%)] Loss: 0.302889\n",
      "Train Epoch: 14 [2368/7119 (33%)] Loss: 0.360654\n",
      "Train Epoch: 14 [2432/7119 (34%)] Loss: 0.229502\n",
      "Train Epoch: 14 [2496/7119 (35%)] Loss: 0.341142\n",
      "Train Epoch: 14 [2560/7119 (36%)] Loss: 0.185946\n",
      "Train Epoch: 14 [2624/7119 (37%)] Loss: 0.450153\n",
      "Train Epoch: 14 [2688/7119 (38%)] Loss: 0.291492\n",
      "Train Epoch: 14 [2752/7119 (39%)] Loss: 0.451150\n",
      "Train Epoch: 14 [2816/7119 (40%)] Loss: 0.331520\n",
      "Train Epoch: 14 [2880/7119 (40%)] Loss: 0.775297\n",
      "Train Epoch: 14 [2944/7119 (41%)] Loss: 0.333400\n",
      "Train Epoch: 14 [3008/7119 (42%)] Loss: 0.513611\n",
      "Train Epoch: 14 [3072/7119 (43%)] Loss: 0.634864\n",
      "Train Epoch: 14 [3136/7119 (44%)] Loss: 0.310272\n",
      "Train Epoch: 14 [3200/7119 (45%)] Loss: 0.555818\n",
      "Train Epoch: 14 [3264/7119 (46%)] Loss: 0.250543\n",
      "Train Epoch: 14 [3328/7119 (47%)] Loss: 0.226717\n",
      "Train Epoch: 14 [3392/7119 (48%)] Loss: 0.518043\n",
      "Train Epoch: 14 [3456/7119 (49%)] Loss: 0.578648\n",
      "Train Epoch: 14 [3520/7119 (49%)] Loss: 0.242028\n",
      "Train Epoch: 14 [3584/7119 (50%)] Loss: 0.485533\n",
      "Train Epoch: 14 [3648/7119 (51%)] Loss: 0.405228\n",
      "Train Epoch: 14 [3712/7119 (52%)] Loss: 0.426500\n",
      "Train Epoch: 14 [3776/7119 (53%)] Loss: 0.432253\n",
      "Train Epoch: 14 [3840/7119 (54%)] Loss: 0.163241\n",
      "Train Epoch: 14 [3904/7119 (55%)] Loss: 0.267420\n",
      "Train Epoch: 14 [3968/7119 (56%)] Loss: 0.308279\n",
      "Train Epoch: 14 [4032/7119 (57%)] Loss: 0.530309\n",
      "Train Epoch: 14 [4096/7119 (58%)] Loss: 0.277273\n",
      "Train Epoch: 14 [4160/7119 (58%)] Loss: 0.477594\n",
      "Train Epoch: 14 [4224/7119 (59%)] Loss: 0.240642\n",
      "Train Epoch: 14 [4288/7119 (60%)] Loss: 0.400117\n",
      "Train Epoch: 14 [4352/7119 (61%)] Loss: 0.111356\n",
      "Train Epoch: 14 [4416/7119 (62%)] Loss: 0.222763\n",
      "Train Epoch: 14 [4480/7119 (63%)] Loss: 0.217068\n",
      "Train Epoch: 14 [4544/7119 (64%)] Loss: 0.301050\n",
      "Train Epoch: 14 [4608/7119 (65%)] Loss: 0.432792\n",
      "Train Epoch: 14 [4672/7119 (66%)] Loss: 0.196107\n",
      "Train Epoch: 14 [4736/7119 (67%)] Loss: 0.307601\n",
      "Train Epoch: 14 [4800/7119 (67%)] Loss: 0.556047\n",
      "Train Epoch: 14 [4864/7119 (68%)] Loss: 0.555755\n",
      "Train Epoch: 14 [4928/7119 (69%)] Loss: 0.153200\n",
      "Train Epoch: 14 [4992/7119 (70%)] Loss: 0.482013\n",
      "Train Epoch: 14 [5056/7119 (71%)] Loss: 0.136683\n",
      "Train Epoch: 14 [5120/7119 (72%)] Loss: 0.174242\n",
      "Train Epoch: 14 [5184/7119 (73%)] Loss: 0.539702\n",
      "Train Epoch: 14 [5248/7119 (74%)] Loss: 0.418644\n",
      "Train Epoch: 14 [5312/7119 (75%)] Loss: 0.082186\n",
      "Train Epoch: 14 [5376/7119 (76%)] Loss: 0.231652\n",
      "Train Epoch: 14 [5440/7119 (76%)] Loss: 0.209694\n",
      "Train Epoch: 14 [5504/7119 (77%)] Loss: 0.203493\n",
      "Train Epoch: 14 [5568/7119 (78%)] Loss: 0.249214\n",
      "Train Epoch: 14 [5632/7119 (79%)] Loss: 0.303466\n",
      "Train Epoch: 14 [5696/7119 (80%)] Loss: 0.335196\n",
      "Train Epoch: 14 [5760/7119 (81%)] Loss: 0.067258\n",
      "Train Epoch: 14 [5824/7119 (82%)] Loss: 0.429603\n",
      "Train Epoch: 14 [5888/7119 (83%)] Loss: 0.252933\n",
      "Train Epoch: 14 [5952/7119 (84%)] Loss: 0.157929\n",
      "Train Epoch: 14 [6016/7119 (85%)] Loss: 0.355489\n",
      "Train Epoch: 14 [6080/7119 (85%)] Loss: 0.380899\n",
      "Train Epoch: 14 [6144/7119 (86%)] Loss: 0.334985\n",
      "Train Epoch: 14 [6208/7119 (87%)] Loss: 0.266941\n",
      "Train Epoch: 14 [6272/7119 (88%)] Loss: 0.159698\n",
      "Train Epoch: 14 [6336/7119 (89%)] Loss: 0.473628\n",
      "Train Epoch: 14 [6400/7119 (90%)] Loss: 0.309687\n",
      "Train Epoch: 14 [6464/7119 (91%)] Loss: 0.088642\n",
      "Train Epoch: 14 [6528/7119 (92%)] Loss: 0.101602\n",
      "Train Epoch: 14 [6592/7119 (93%)] Loss: 0.117072\n",
      "Train Epoch: 14 [6656/7119 (93%)] Loss: 0.281786\n",
      "Train Epoch: 14 [6720/7119 (94%)] Loss: 0.320633\n",
      "Train Epoch: 14 [6784/7119 (95%)] Loss: 0.283491\n",
      "Train Epoch: 14 [6848/7119 (96%)] Loss: 0.114432\n",
      "Train Epoch: 14 [6912/7119 (97%)] Loss: 0.215002\n",
      "Train Epoch: 14 [6976/7119 (98%)] Loss: 0.318350\n",
      "Train Epoch: 14 [7040/7119 (99%)] Loss: 0.243770\n",
      "Train Epoch: 14 [7104/7119 (100%)] Loss: 0.563914\n",
      "    epoch          : 14\n",
      "    loss           : 0.31915996541802805\n",
      "    accuracy       : 0.8649906367041199\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.2513686515390873\n",
      "    val_accuracy   : 0.8975\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch14.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 15 [0/7119 (0%)] Loss: 0.778435\n",
      "Train Epoch: 15 [64/7119 (1%)] Loss: 0.740311\n",
      "Train Epoch: 15 [128/7119 (2%)] Loss: 0.208590\n",
      "Train Epoch: 15 [192/7119 (3%)] Loss: 0.196775\n",
      "Train Epoch: 15 [256/7119 (4%)] Loss: 0.283833\n",
      "Train Epoch: 15 [320/7119 (4%)] Loss: 0.062534\n",
      "Train Epoch: 15 [384/7119 (5%)] Loss: 0.212843\n",
      "Train Epoch: 15 [448/7119 (6%)] Loss: 0.207689\n",
      "Train Epoch: 15 [512/7119 (7%)] Loss: 0.291230\n",
      "Train Epoch: 15 [576/7119 (8%)] Loss: 0.371666\n",
      "Train Epoch: 15 [640/7119 (9%)] Loss: 0.221373\n",
      "Train Epoch: 15 [704/7119 (10%)] Loss: 0.176926\n",
      "Train Epoch: 15 [768/7119 (11%)] Loss: 0.675894\n",
      "Train Epoch: 15 [832/7119 (12%)] Loss: 0.308871\n",
      "Train Epoch: 15 [896/7119 (13%)] Loss: 0.175595\n",
      "Train Epoch: 15 [960/7119 (13%)] Loss: 0.109895\n",
      "Train Epoch: 15 [1024/7119 (14%)] Loss: 0.608779\n",
      "Train Epoch: 15 [1088/7119 (15%)] Loss: 0.116173\n",
      "Train Epoch: 15 [1152/7119 (16%)] Loss: 0.359917\n",
      "Train Epoch: 15 [1216/7119 (17%)] Loss: 0.167643\n",
      "Train Epoch: 15 [1280/7119 (18%)] Loss: 0.610735\n",
      "Train Epoch: 15 [1344/7119 (19%)] Loss: 0.454784\n",
      "Train Epoch: 15 [1408/7119 (20%)] Loss: 0.157829\n",
      "Train Epoch: 15 [1472/7119 (21%)] Loss: 0.354554\n",
      "Train Epoch: 15 [1536/7119 (22%)] Loss: 0.464103\n",
      "Train Epoch: 15 [1600/7119 (22%)] Loss: 0.139980\n",
      "Train Epoch: 15 [1664/7119 (23%)] Loss: 0.159789\n",
      "Train Epoch: 15 [1728/7119 (24%)] Loss: 0.631423\n",
      "Train Epoch: 15 [1792/7119 (25%)] Loss: 0.296128\n",
      "Train Epoch: 15 [1856/7119 (26%)] Loss: 0.507844\n",
      "Train Epoch: 15 [1920/7119 (27%)] Loss: 0.453847\n",
      "Train Epoch: 15 [1984/7119 (28%)] Loss: 0.132138\n",
      "Train Epoch: 15 [2048/7119 (29%)] Loss: 0.318256\n",
      "Train Epoch: 15 [2112/7119 (30%)] Loss: 0.231032\n",
      "Train Epoch: 15 [2176/7119 (31%)] Loss: 0.232555\n",
      "Train Epoch: 15 [2240/7119 (31%)] Loss: 0.147971\n",
      "Train Epoch: 15 [2304/7119 (32%)] Loss: 0.299070\n",
      "Train Epoch: 15 [2368/7119 (33%)] Loss: 0.111746\n",
      "Train Epoch: 15 [2432/7119 (34%)] Loss: 0.720006\n",
      "Train Epoch: 15 [2496/7119 (35%)] Loss: 0.424474\n",
      "Train Epoch: 15 [2560/7119 (36%)] Loss: 0.183912\n",
      "Train Epoch: 15 [2624/7119 (37%)] Loss: 0.158561\n",
      "Train Epoch: 15 [2688/7119 (38%)] Loss: 0.074837\n",
      "Train Epoch: 15 [2752/7119 (39%)] Loss: 0.421562\n",
      "Train Epoch: 15 [2816/7119 (40%)] Loss: 0.380494\n",
      "Train Epoch: 15 [2880/7119 (40%)] Loss: 0.097238\n",
      "Train Epoch: 15 [2944/7119 (41%)] Loss: 0.200535\n",
      "Train Epoch: 15 [3008/7119 (42%)] Loss: 0.232216\n",
      "Train Epoch: 15 [3072/7119 (43%)] Loss: 0.431261\n",
      "Train Epoch: 15 [3136/7119 (44%)] Loss: 0.524945\n",
      "Train Epoch: 15 [3200/7119 (45%)] Loss: 0.613262\n",
      "Train Epoch: 15 [3264/7119 (46%)] Loss: 0.291514\n",
      "Train Epoch: 15 [3328/7119 (47%)] Loss: 0.165131\n",
      "Train Epoch: 15 [3392/7119 (48%)] Loss: 0.223837\n",
      "Train Epoch: 15 [3456/7119 (49%)] Loss: 0.316519\n",
      "Train Epoch: 15 [3520/7119 (49%)] Loss: 0.228087\n",
      "Train Epoch: 15 [3584/7119 (50%)] Loss: 0.263622\n",
      "Train Epoch: 15 [3648/7119 (51%)] Loss: 0.346042\n",
      "Train Epoch: 15 [3712/7119 (52%)] Loss: 0.325963\n",
      "Train Epoch: 15 [3776/7119 (53%)] Loss: 0.198649\n",
      "Train Epoch: 15 [3840/7119 (54%)] Loss: 0.447620\n",
      "Train Epoch: 15 [3904/7119 (55%)] Loss: 0.343248\n",
      "Train Epoch: 15 [3968/7119 (56%)] Loss: 0.357853\n",
      "Train Epoch: 15 [4032/7119 (57%)] Loss: 0.150793\n",
      "Train Epoch: 15 [4096/7119 (58%)] Loss: 0.535624\n",
      "Train Epoch: 15 [4160/7119 (58%)] Loss: 0.474434\n",
      "Train Epoch: 15 [4224/7119 (59%)] Loss: 0.104033\n",
      "Train Epoch: 15 [4288/7119 (60%)] Loss: 0.208593\n",
      "Train Epoch: 15 [4352/7119 (61%)] Loss: 0.174114\n",
      "Train Epoch: 15 [4416/7119 (62%)] Loss: 0.398884\n",
      "Train Epoch: 15 [4480/7119 (63%)] Loss: 0.456153\n",
      "Train Epoch: 15 [4544/7119 (64%)] Loss: 0.414771\n",
      "Train Epoch: 15 [4608/7119 (65%)] Loss: 0.299032\n",
      "Train Epoch: 15 [4672/7119 (66%)] Loss: 0.225246\n",
      "Train Epoch: 15 [4736/7119 (67%)] Loss: 0.314701\n",
      "Train Epoch: 15 [4800/7119 (67%)] Loss: 0.311221\n",
      "Train Epoch: 15 [4864/7119 (68%)] Loss: 0.218376\n",
      "Train Epoch: 15 [4928/7119 (69%)] Loss: 0.514052\n",
      "Train Epoch: 15 [4992/7119 (70%)] Loss: 0.378301\n",
      "Train Epoch: 15 [5056/7119 (71%)] Loss: 0.264186\n",
      "Train Epoch: 15 [5120/7119 (72%)] Loss: 0.297766\n",
      "Train Epoch: 15 [5184/7119 (73%)] Loss: 0.217948\n",
      "Train Epoch: 15 [5248/7119 (74%)] Loss: 0.302114\n",
      "Train Epoch: 15 [5312/7119 (75%)] Loss: 0.138333\n",
      "Train Epoch: 15 [5376/7119 (76%)] Loss: 0.309088\n",
      "Train Epoch: 15 [5440/7119 (76%)] Loss: 0.307961\n",
      "Train Epoch: 15 [5504/7119 (77%)] Loss: 0.168716\n",
      "Train Epoch: 15 [5568/7119 (78%)] Loss: 0.292138\n",
      "Train Epoch: 15 [5632/7119 (79%)] Loss: 0.356085\n",
      "Train Epoch: 15 [5696/7119 (80%)] Loss: 0.080447\n",
      "Train Epoch: 15 [5760/7119 (81%)] Loss: 0.528832\n",
      "Train Epoch: 15 [5824/7119 (82%)] Loss: 0.451873\n",
      "Train Epoch: 15 [5888/7119 (83%)] Loss: 0.587647\n",
      "Train Epoch: 15 [5952/7119 (84%)] Loss: 0.224418\n",
      "Train Epoch: 15 [6016/7119 (85%)] Loss: 0.572684\n",
      "Train Epoch: 15 [6080/7119 (85%)] Loss: 0.273135\n",
      "Train Epoch: 15 [6144/7119 (86%)] Loss: 0.180827\n",
      "Train Epoch: 15 [6208/7119 (87%)] Loss: 0.589716\n",
      "Train Epoch: 15 [6272/7119 (88%)] Loss: 0.243986\n",
      "Train Epoch: 15 [6336/7119 (89%)] Loss: 0.125728\n",
      "Train Epoch: 15 [6400/7119 (90%)] Loss: 0.351908\n",
      "Train Epoch: 15 [6464/7119 (91%)] Loss: 0.108816\n",
      "Train Epoch: 15 [6528/7119 (92%)] Loss: 0.176235\n",
      "Train Epoch: 15 [6592/7119 (93%)] Loss: 0.231664\n",
      "Train Epoch: 15 [6656/7119 (93%)] Loss: 0.143091\n",
      "Train Epoch: 15 [6720/7119 (94%)] Loss: 0.079890\n",
      "Train Epoch: 15 [6784/7119 (95%)] Loss: 0.279843\n",
      "Train Epoch: 15 [6848/7119 (96%)] Loss: 0.249694\n",
      "Train Epoch: 15 [6912/7119 (97%)] Loss: 0.354136\n",
      "Train Epoch: 15 [6976/7119 (98%)] Loss: 0.394218\n",
      "Train Epoch: 15 [7040/7119 (99%)] Loss: 0.449825\n",
      "Train Epoch: 15 [7104/7119 (100%)] Loss: 0.392794\n",
      "    epoch          : 15\n",
      "    loss           : 0.3090121175884531\n",
      "    accuracy       : 0.8665449438202247\n",
      "    top_k_acc      : 1.0\n",
      "    val_loss       : 0.2657401286065578\n",
      "    val_accuracy   : 0.90875\n",
      "    val_top_k_acc  : 1.0\n",
      "Saving checkpoint: saved/models/BCDensenet/0617_002401/checkpoint-epoch15.pth ...\n"
     ]
    }
   ],
   "source": [
    "# Train classifier\n",
    "!python train.py --config config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "494fc022-d27f-4e14-9257-f61d0e4bf1ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:05:38.154260Z",
     "iopub.status.busy": "2025-06-17T01:05:38.153946Z",
     "iopub.status.idle": "2025-06-17T01:05:38.157736Z",
     "shell.execute_reply": "2025-06-17T01:05:38.157230Z",
     "shell.execute_reply.started": "2025-06-17T01:05:38.154241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/breast_cancer_detection\n",
      "['0224_034642', '0617_002401']\n"
     ]
    }
   ],
   "source": [
    "# Verify output directory & save trained model\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/sagemaker-user/breast_cancer_detection')\n",
    "print(os.listdir('saved/models/BCDensenet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5cf170-ffa4-4876-85ad-205d9ad97b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:22:15.952887Z",
     "iopub.status.busy": "2025-06-17T01:22:15.952239Z",
     "iopub.status.idle": "2025-06-17T01:22:39.361671Z",
     "shell.execute_reply": "2025-06-17T01:22:39.360972Z",
     "shell.execute_reply.started": "2025-06-17T01:22:15.952858Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/breast_cancer_detection/my_model.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "os.chdir('/home/sagemaker-user/breast_cancer_detection')\n",
    "shutil.make_archive('my_model', 'zip', 'saved/models/BCDensenet/0617_002401')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
